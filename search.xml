<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[[剑指offer]-复杂链表的复制]]></title>
    <url>%2F2019%2F06%2F17%2F%E5%89%91%E6%8C%87offer-%E5%A4%8D%E6%9D%82%E9%93%BE%E8%A1%A8%E7%9A%84%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[题目描述输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的head。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空） 思路：(在不借助辅助空间的情况下，实现O(n)的时间效率)分为三步走： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/*struct RandomListNode &#123; int label; struct RandomListNode *next, *random; RandomListNode(int x) : label(x), next(NULL), random(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: RandomListNode* Clone(RandomListNode* pHead) &#123; if(pHead == NULL) return NULL; //第一步：遍历链表，复制每个结点，如复制结点A得到A1，将结点A1插到结点A后面； RandomListNode* curNode = pHead; while(curNode != NULL)&#123; RandomListNode* pCloned = new RandomListNode(0); pCloned-&gt;label = curNode-&gt;label; pCloned-&gt;next = curNode-&gt;next; pCloned-&gt;random = NULL; curNode-&gt;next = pCloned; curNode = pCloned-&gt;next; &#125; //第二步：重新遍历链表，复制老结点的随机指针给新结点，如A1.random = A.random.next; curNode = pHead; while(curNode != NULL)&#123; RandomListNode* pCloned = curNode-&gt;next; if(curNode-&gt;random != NULL)&#123; //！！！！很关键的一个判断，不然就出现野指针 pCloned-&gt;random = curNode-&gt;random-&gt;next; &#125; curNode = pCloned-&gt;next; &#125; //第三步：拆分链表，将链表拆分为原链表和复制后的链表 curNode = pHead; RandomListNode* pCloneHead = pHead-&gt;next; while(curNode != NULL)&#123; RandomListNode* pCloneNode = curNode-&gt;next; //临时存放当前节点的下一个指针 curNode-&gt;next = curNode-&gt;next-&gt;next; //原始链表，隔一个节点连接一个 //复制后链表，隔一个节点连接一个，但是要考虑该节点是最后一个的情况 pCloneNode-&gt;next = pCloneNode-&gt;next == NULL?NULL:pCloneNode-&gt;next-&gt;next; curNode = curNode-&gt;next; //移到下一个原始节点 &#125; return pCloneHead; &#125;&#125;;]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>剑指offer</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[剑指offer]-圆圈中最后剩下的数]]></title>
    <url>%2F2019%2F06%2F17%2F%E5%89%91%E6%8C%87offer-%E5%9C%86%E5%9C%88%E4%B8%AD%E6%9C%80%E5%90%8E%E5%89%A9%E4%B8%8B%E7%9A%84%E6%95%B0%2F</url>
    <content type="text"><![CDATA[题目：圆圈中最后剩下的数 题目：0，1，n-1这n个数字排成一个圆圈，从数字0开始，每次从这个圆圈里删除第m个数字。求出这个圆圈里剩下的最后一个数字。 思路：用约瑟夫环的思想例如，0、1、2、3、4这5个数字组成一个圆圈（如图6.3所示），从数字0开始每次删除第3个数字，则删除的前4个数字依次是2、0、4、1，因此最后剩下的数字是3。 可以用模板库中的std:list来模拟一个环形链表。由于std:：list本身并不是一个环形结构，因此每当迭代器（Iterator）扫描到链表末尾的时候，我们要记得把迭代器移到链表的头部。 123456789101112131415161718192021222324252627class Solution &#123;public: int LastRemaining_Solution(int n, int m) &#123; if (n &lt; 1 || m &lt; 1) return -1; list&lt;int&gt; mlist; for (int i = 0; i &lt; n; i++) mlist.push_back(i); long count = 0; auto it = mlist.begin(); int k = m - 1; while (mlist.size() &gt; 1) &#123; while (k--) &#123; it++; if (it == mlist.end()) it = mlist.begin(); &#125; it = mlist.erase(it); if (it == mlist.end()) it = mlist.begin(); k = m - 1; &#125; return mlist.front(); &#125;&#125;;]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>剑指offer</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[剑指offer]-合并两个排序的链表]]></title>
    <url>%2F2019%2F06%2F17%2F%E5%89%91%E6%8C%87offer-%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%8E%92%E5%BA%8F%E7%9A%84%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[题目描述输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。 123456789101112131415161718192021222324252627282930313233343536373839/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* Merge(ListNode* pHead1, ListNode* pHead2) &#123; if(pHead1 ==NULL) return pHead2; if(pHead2 == NULL) return pHead1; ListNode* pre_head = new ListNode(0); ListNode* pTemp = pre_head; while(pHead1 !=NULL &amp;&amp; pHead2 != NULL)&#123; if(pHead1-&gt;val &lt; pHead2-&gt;val)&#123; pTemp-&gt;next = pHead1; pHead1 = pHead1-&gt;next; &#125; else&#123; pTemp-&gt;next = pHead2; pHead2 = pHead2-&gt;next; &#125; pTemp = pTemp-&gt;next; &#125; //将比较后某一个原始链表剩余部分直接插到新的链表后方 if(pHead1) pTemp-&gt;next = pHead1; if(pHead2) pTemp-&gt;next = pHead2; ListNode* ans = pre_head-&gt;next; delete pre_head; return ans; &#125;&#125;;]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>剑指offer</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[剑指offer]-链表中倒数第K个节点]]></title>
    <url>%2F2019%2F06%2F17%2F%E5%89%91%E6%8C%87offer-%E9%93%BE%E8%A1%A8%E4%B8%AD%E5%80%92%E6%95%B0%E7%AC%ACK%E4%B8%AA%E8%8A%82%E7%82%B9%2F</url>
    <content type="text"><![CDATA[题目：输入一个链表，输出该链表中倒数第k个结点。 思路：快慢指针 123456789101112131415161718192021222324252627/*struct ListNode &#123; int val; struct ListNode *next; ListNode(int x) : val(x), next(NULL) &#123; &#125;&#125;;*/class Solution &#123;public: ListNode* FindKthToTail(ListNode* pListHead, unsigned int k) &#123; ListNode* fast = pListHead; ListNode* low = pListHead; while(k &gt; 0)&#123; if(fast == NULL)&#123; return NULL; //防止越界错误！！！要加 &#125; fast = fast-&gt;next; k--; &#125; while(fast != NULL)&#123; fast = fast-&gt;next; low = low-&gt;next; &#125; return low; &#125;&#125;;]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>剑指offer</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[剑指offer]-从尾到头打印链表]]></title>
    <url>%2F2019%2F06%2F17%2F%E5%89%91%E6%8C%87offer-%E4%BB%8E%E5%B0%BE%E5%88%B0%E5%A4%B4%E6%89%93%E5%8D%B0%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[题目描述输入一个链表，按链表值从尾到头的顺序返回一个ArrayList。 思路分析：其实本题和链表逆序很类似，链表逆序要求改变链表，采用头插法。此题逆序打印链表，一般理解为不改变链表结构，因此采用栈的结构。 1234567891011121314151617181920212223242526272829/*** struct ListNode &#123;* int val;* struct ListNode *next;* ListNode(int x) :* val(x), next(NULL) &#123;* &#125;* &#125;;*/#include &lt;stack&gt;#include &lt;vector&gt;class Solution &#123;public: vector&lt;int&gt; printListFromTailToHead(ListNode* head) &#123; std::stack&lt;ListNode*&gt; nodes; vector&lt;int&gt; mVector; ListNode* pNodes = head; while(pNodes != NULL)&#123; nodes.push(pNodes); pNodes = pNodes-&gt;next; &#125; while(!nodes.empty())&#123; pNodes = nodes.top(); mVector.push_back(pNodes-&gt;val); nodes.pop(); &#125; return mVector; &#125;&#125;;]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>剑指offer</category>
      </categories>
      <tags>
        <tag>剑指offer</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统-内存管理]]></title>
    <url>%2F2019%2F03%2F22%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[2.1逻辑地址空间与物理地址空间Eg：编译时只需确定变量x存放的相对地址是100（也就是说相对于进程在内存中的起始地址而言的地址）。CPU想要找到x在内存中的实际存放位置，只需要用进程的起始地址+100即可。 相对地址又称逻辑地址，绝对地址又称物理地址。 编译后，每个目标模块都是从0号单元开始编址，称为该目标模块的相对地址（或逻辑地址）。 当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按各个模块的相对地址构成统一的从0号单元开始编址的逻辑地址空间。 物理地址空间是指内存中物理单元的集合，它是地址转换的最终地址，进程在运行时执行指令和访问数据最后都要通过物理地址来存取主存。当装入程序将可执行代码装入内存时，必须通过地址转换将逻辑地址转换成物理地址，这个过程称为地址重定位。 2.2内存分配管理方式内存分配管理方式包括连续分配管理方式与非连续分配管理方式。 连续分配方式，是指为一个用户程序分配一个连续的内存空间。它主要包括单一连续分配、固定分区分配和动态分区分配。 非连续分配管理方式允许一个程序分散地装入到不相邻的内存分区中，根据分区的大小是否固定分为分页存储管理方式和分段存储管理方式。分页存储管理方式中，又根据运行作业时是否要把作业的所有页面都装入内存才能运行分为基本分页存储管理方式和请求分页存储管理方式。 2.2.1基本分页存储管理方式固定分区会产生内部碎片，动态分区会产生外部碎片，这两种技术对内存的利用率都比较低。我们希望内存的使用能尽量避免碎片的产生，这就引入了分页的思想：把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间。 分页的方法从形式上看，像分区相等的固定分区技术，分页管理不会产生外部碎片。但它又有本 质的不同点：块的大小相对分区要小很多，而且进程也按照块进行划分，进程运行时按块申请主存可用空间并执行。这样，进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片，所以尽管会产生内部碎片，但是这种碎片相对于进程来说也是很小的，每个进程平均只产生半个块大小的内部碎片（也称页内碎片）。 1）分页存储的几个基本概念 ①页面和页面大小。进程中的块称为页（Page），内存中的块称为页框（Page Frame，或页帧）。外存也以同样的单位进行划分，称为块（Block）。进程在执行时需要申请主存空间，就是要为每个页面分配主存中的可用页框，这就产生了页和页框的一一对应。 为方便地址转换，页面大小应是2的整数幂。同时页面大小应该适中，如果页面太小，会使进程的页面数过多，这样页表就过长，占用大量内存，而且也会增加硬件地址转换的开销，降低页面换/ 换出的效率；页面过大又会使页面内碎片增大，降低内存的利用率。所以页面的大小应该适中，考虑到空间效率和时间效率的权衡。 ②地址结构。分页存储管理的逻辑地址结构如下图所示： 地址结构包含两部分：前一部分为页号P，后一部分为页内偏移量M。地址长度为32位，其中0～11位为页内地址，即每页大小为4KB；12~31位为页号，地址空间最多允许有2^20页。 ③页表。为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表，记录页面在内存中对应的物理块号，页表一般存放在内存中。在配置了页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，页表的作用是实现从页号到物理块号的地址映射。 如何计算(以手动计算为例)： 页号=逻辑地址/页面长度（取除法的整数部分） 页内偏移量=逻辑地址%页面长度（取除法的余数部分） 页面在内存中的起始位置：操作系统需要用某种数据结构记录进程各个页面的起始位置。 存在页表中 页号=80/50=1 页内偏移量=80%50=3 01号页在内存中存放的起始位置450 物理地址为450+3=453 2.2.2基本分段存储管理方式段式管理方式按照用户进程中的自然段划分逻辑空间。例如，用户进程由主程序、两个子程序、栈和一段数据组成，于是可以把这个用户进程划分为5个段，每段从0开始编址，并分配一段连续的地址空间（段内要求连续，段间不要求连续，因此整个作业的地址空间是二维的）。其逻辑地址由段号S与段内偏移量W两部分组成。 在下图中，段号为16位，段内偏移量为16位，则一个作业最多可有216-65536个段，最大段长为64KB。 在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必须由用户显示提供，在高级程序设计语言中，这个工作由编译程序完成。 2.2.3段页式管理方式页式存储管理能有效地提高内存利用率，而分段存储管理能反映程序的逻辑结构并有利于段的共享。如果将这两种存储管理方法结合起来，就形成了段页式存储管理方式。 在段页式系统中，作业的地址空间首先被分成若干逻辑段，每段都有自己的段号，然后再将每一段分成若干大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干和页面大小相同的存储块，对内存的分配以存储块为单位。 在段页式系统中，作业的逻辑地址分为三部分：段号、页号和页内偏移量。为了实现地址变换，系统为每个进程建立一张段表，而每个分段有一张页表。段表表项中至少包括段号、页表长度和页表起始地址，页表表项中至少包括页号和块号。此外，系统中还应有一个段表寄存器，指出作业的段表起始地址和段表长度。 在进行地址变换时，首先通过段表查到页表起始地址，然后通过页表找到页帧号，最后形成物理地址。 例1：关于段页式管理中，地址映像表是（）。 A.每个进程一张段表，一张页表B.进程的每个段一张段表，一张页表C.每个进程一张段表，每个段一张页表D.每个进程一张页表，每个段一张段表解答：C。 2.3虚拟内存管理上一节所讨论的各种内存管理策略都是为了同时将多个进程保存在内存中以便允许多道程序设计。它们都具有以下两个共同的特征：作业必须一次性全部装入内存后，方能开始运行；驻留性：作业被装入内存后，就一直驻留在内存中，其任何部分都不会被换出，直至作业运行结束。 由以上分析可知，许多在程序运行中不用或暂时不用的程序（数据）占据了大量的内存空间，而一些需要运行的作业又无法装入运行，显然浪费了宝贵的内存资源。 2.3.1虚拟存储器的定义和特征基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。 之所以将其称为虚拟存储器，是因为这种存储器实际上并不存在，只是由于系统提供了部分装入、请求调入和置换功能后（对用户完全透明），给用户的感觉是好像存在一个比实际物理内存大得多的存储器。 虚拟内存的实现有以下三种方式： 1）请求分页存储管理。 2）请求分段存储管理。 3）请求段页式存储管理。 不管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面： 1）一定容量的内存和外存。 2）页表机制（或段表机制），作为主要的数据结构。 3）中断机构，当用户程序要访问的部分尚未调入内存，则产生中断。 4）地址变换机构，逻辑地址到物理地址的变换。 例1：段页式虚拟存储管理方案的特点是（）。（2012·腾讯） A.空间浪费大、存储共享不易，存储保护容易、不能动态链接 B.空间浪费小、存储共享容易、存储保护不易、不能动态链接 C.空间浪费大、存储共享不易、存储保护容易、能动态链接 D.空间浪费小、存储共享容易、存储保护容易、能动态链接 解答：D。为了能够同时获得段式虚拟存储器在程序模块化方面的优点和页式虚拟存储器在管理主存和辅存物理空间方面的优点，把两种虚拟存储器结合起来就成为段页式虚拟存储器。其基本思想是对用户原来编写程序的虚拟存储空间采用分段的方法管理，而对主存储器的物理空间采用分页的方法管理。 段页式虚拟存储器一方面具有段式虚拟存储器的主要优点。例如，用户程序可以模块化编写，程序段的共享和信息的保护都比较方便，程序可以在执行时再动态链接等。 另一方面也具有页式虚拟存储器的主要优点。例如：主存储器的利用率比较高，对辅助存储器的管理比较容易等。 2.3.2请求分页管理方式请求分页系统建立在基本分页系统基础之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。 在请求分页系统中，只要求将当前需要的一部分页面装入内存，便可以启动作业运行。在作业执行过程中，当所要访问的页面不在内存时，再通过调页功能将其调入，同时还可以通过置换功能将暂时不用的页面换出到外存上，以便腾出内存空间。 为了实现请求分页，系统必须提供一定的硬件支持。除了需要一定容量的内存及外存的计算机系统，还需要有页表机制、缺页中断机构和地址变换机构。 常见的置换算法有以下三种：最佳置换算法、先进先出（FIFO）页面置换算法、最近最久未使用（LRU）置换算法。 2.4抖动：在页面置换过程中的一种最糟糕的情形是，刚刚换出的页面马上又要换入主存，刚刚换入的页面马上就要换出主存，这种频繁的页面调度行为称为抖动，或颠簸。如果一个进程在换页上用的时间多于执行时间，那么这个进程就在颠簸。 频繁的发生缺页中断，其主要原因是某个进程频繁访问的页面数目高于可用的物理页帧数目。]]></content>
      <categories>
        <category>操作系统</category>
        <category>操作系统概念</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统-死锁]]></title>
    <url>%2F2019%2F03%2F21%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[所谓死锁是指多个进程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都 将无法向前推进。现实生活中简单的例子：交通阻塞，两股相向而行的车流都想通过已被对方占用的道路，结果双方都不能前进。 1.死锁产生的原因1）系统资源的竞争 2）进程推进顺序非法 2.死锁产生的必要条件产生死锁必须同时满足以下四个条件，只要其中任一条件不成立，死锁就不会发生。 互斥条件：进程要求对所分配的资源进行排他性控制，即在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。 不剥夺条件：进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放。 请求和保持条件：又称为部分分配条件。进程每次申请它所需要的一部分资源，在等待新资源的同时，进程继续占有已分配到的资源。 循环等待条件：存在一种进程资源的循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。即存在一个处于等待状态的进程集合{P1，P2，P3，…，Pa}，其中P，等待的资源被P1（i-0，1，…，n-1）占有，Pn等待资源被P0占有。 例1：产生死锁的必要条件有（）。（2013·腾讯、2012·百度简答题） A.互斥条件 B.请求和保持条件 C.不可剥夺条件 D.循环等待条件 解答：ABCD。 例2：若系统中有6个队列，有多个进程均需要使用其中的3个，规定每个进程一次只允许申请一个队列，那么最多允许（）进程参与竞争，才不会造成死锁？（2012·淘宝） A.1个 B.2个 C.3个 D.4个 解答：B。设想如果有3个进程参与竞争，刚好每个进程都持有2个队列，这样系统中所有队列就全部被使用，3个进程都缺少一个队列完成任务，因而都无法继续进行下去，发生了死锁。 3.死锁处理策略1）预防死锁：设置某些限制条件，破坏产生死锁的四个必要条件中的一个或几个。 2）避免死锁：在资源的动态分配过程中，用某种方法防止系统进入不安全状态。银行家算法是著名的死锁避免算法。 3）死锁的检测及解除：无须采取任何限制性措施，允许进程在运行过程中发生死锁，通过系统的检测机制及时地检测出死锁的发生，然后采取某种措施解除死锁。死锁的检测可利用资源分配图来描述。死锁的解除主要方法如下： （1）资源剥夺法。 （2）撤销进程法。 （3）进程回退法。 例1：避免死锁的一个著名的算法是（）。（2012·腾讯） A.先入先出法 B.银行家算法 C.优先级算法 D.资源按序分配法 解答：B。]]></content>
      <categories>
        <category>操作系统</category>
        <category>操作系统概念</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux]]></title>
    <url>%2F2019%2F03%2F20%2FLinux%2F</url>
    <content type="text"><![CDATA[一、常用操作以及概念快捷键 Tab：命令和文件名补全； Ctrl+C：中断正在运行的程序； Ctrl+D：结束键盘输入（End Of File，EOF） 求助1. –help指令的基本用法与选项介绍。 2. manman 是 manual 的缩写，将指令的具体信息显示出来。 当执行 man date 时，有 DATE(1) 出现，其中的数字代表指令的类型，常用的数字及其类型如下： 代号 类型 1 用户在 shell 环境中可以操作的指令或者可执行文件 5 配置文件 8 系统管理员可以使用的管理指令 3. infoinfo 与 man 类似，但是 info 将文档分成一个个页面，每个页面可以进行跳转。 4. doc/usr/share/doc 存放着软件的一整套说明文件。 关机1. who在关机前需要先使用 who 命令查看有没有其它用户在线。 2. sync为了加快对磁盘文件的读写速度，位于内存中的文件数据不会立即同步到磁盘上，因此关机之前需要先进行 sync 同步操作。 3. shutdown12345# shutdown [-krhc] 时间 [信息]-k ： 不会关机，只是发送警告信息，通知所有在线的用户-r ： 将系统的服务停掉后就重新启动-h ： 将系统的服务停掉后就立即关机-c ： 取消已经在进行的 shutdown 指令内容 PATH可以在环境变量 PATH 中声明可执行文件的路径，路径之间用 : 分隔。 1/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/dmtsai/.local/bin:/home/dmtsai/bin sudosudo 允许一般用户使用 root 可执行的命令，不过只有在 /etc/sudoers 配置文件中添加的用户才能使用该指令。 包管理工具RPM 和 DPKG 为最常见的两类软件包管理工具： RPM 全称为 Redhat Package Manager，最早由 Red Hat 公司制定实施，随后被 GNU 开源操作系统接受并成为许多 Linux 系统的既定软件标准。YUM 基于 RPM，具有依赖管理和软件升级功能。 与 RPM 竞争的是基于 Debian 操作系统的 DEB 软件包管理工具 DPKG，全称为 Debian Package，功能方面与 RPM 相似。 发行版Linux 发行版是 Linux 内核及各种应用软件的集成版本。 基于的包管理工具 商业发行版 社区发行版 RPM Red Hat Fedora / CentOS DPKG Ubuntu Debian VIM 三个模式 一般指令模式（Command mode）：VIM 的默认模式，可以用于移动游标查看内容； 编辑模式（Insert mode）：按下 “i” 等按键之后进入，可以对文本进行编辑； 指令列模式（Bottom-line mode）：按下 “:” 按键之后进入，用于保存退出等操作。 在指令列模式下，有以下命令用于离开或者保存文件。 命令 作用 :w 写入磁盘 :w! 当文件为只读时，强制写入磁盘。到底能不能写入，与用户对该文件的权限有关 :q 离开 :q! 强制离开不保存 :wq 写入磁盘后离开 :wq! 强制写入磁盘后离开 GNUGNU 计划，译为革奴计划，它的目标是创建一套完全自由的操作系统，称为 GNU，其内容软件完全以 GPL 方式发布。其中 GPL 全称为 GNU 通用公共许可协议（GNU General Public License），包含了以下内容： 以任何目的运行此程序的自由； 再复制的自由； 改进此程序，并公开发布改进的自由。 开源协议 Choose an open source license 如何选择开源许可证？ 二、磁盘磁盘接口磁盘的文件名Linux 中每个硬件都被当做一个文件，包括磁盘。磁盘以磁盘接口类型进行命名，常见磁盘的文件名如下： IDE 磁盘：/dev/hd[a-d] SATA/SCSI/SAS 磁盘：/dev/sd[a-p] 其中文件名后面的序号的确定与系统检测到磁盘的顺序有关，而与磁盘所插入的插槽位置无关。 三、分区分区表磁盘分区表主要有两种格式，一种是限制较多的 MBR 分区表，一种是较新且限制较少的 GPT 分区表。 1. MBRMBR 中，第一个扇区最重要，里面有主要开机记录（Master boot record, MBR）及分区表（partition table），其中主要开机记录占 446 bytes，分区表占 64 bytes。 分区表只有 64 bytes，最多只能存储 4 个分区，这 4 个分区为主分区（Primary）和扩展分区（Extended）。其中扩展分区只有一个，它使用其它扇区来记录额外的分区表，因此通过扩展分区可以分出更多分区，这些分区称为逻辑分区。 Linux 也把分区当成文件，分区文件的命名方式为：磁盘文件名 + 编号，例如 /dev/sda1。注意，逻辑分区的编号从 5 开始。 2. GPT扇区是磁盘的最小存储单位，旧磁盘的扇区大小通常为 512 bytes，而最新的磁盘支持 4 k。GPT 为了兼容所有磁盘，在定义扇区上使用逻辑区块地址（Logical Block Address, LBA），LBA 默认大小为 512 bytes。 GPT 第 1 个区块记录了主要开机记录（MBR），紧接着是 33 个区块记录分区信息，并把最后的 33 个区块用于对分区信息进行备份。这 33 个区块第一个为 GPT 表头纪录，这个部份纪录了分区表本身的位置与大小和备份分区的位置，同时放置了分区表的校验码 (CRC32)，操作系统可以根据这个校验码来判断 GPT 是否正确。若有错误，可以使用备份分区进行恢复。 GPT 没有扩展分区概念，都是主分区，每个 LBA 可以分 4 个分区，因此总共可以分 4 * 32 = 128 个分区。 MBR 不支持 2.2 TB 以上的硬盘，GPT 则最多支持到 233 TB = 8 ZB。 开机检测程序1. BIOSBIOS（Basic Input/Output System，基本输入输出系统），它是一个固件（嵌入在硬件中的软件），BIOS 程序存放在断电后内容不会丢失的只读内存中。 BIOS 是开机的时候计算机执行的第一个程序，这个程序知道可以开机的磁盘，并读取磁盘第一个扇区的主要开机记录（MBR），由主要开机记录（MBR）执行其中的开机管理程序，这个开机管理程序会加载操作系统的核心文件。 主要开机记录（MBR）中的开机管理程序提供以下功能：选单、载入核心文件以及转交其它开机管理程序。转交这个功能可以用来实现多重引导，只需要将另一个操作系统的开机管理程序安装在其它分区的启动扇区上，在启动开机管理程序时，就可以通过选单选择启动当前的操作系统或者转交给其它开机管理程序从而启动另一个操作系统。 下图中，第一扇区的主要开机记录（MBR）中的开机管理程序提供了两个选单：M1、M2，M1 指向了 Windows 操作系统，而 M2 指向其它分区的启动扇区，里面包含了另外一个开机管理程序，提供了一个指向 Linux 的选单。 安装多重引导，最好先安装 Windows 再安装 Linux。因为安装 Windows 时会覆盖掉主要开机记录（MBR），而 Linux 可以选择将开机管理程序安装在主要开机记录（MBR）或者其它分区的启动扇区，并且可以设置开机管理程序的选单。 2. UEFIBIOS 不可以读取 GPT 分区表，而 UEFI 可以。 四、文件系统分区与文件系统对分区进行格式化是为了在分区上建立文件系统。一个分区通常只能格式化为一个文件系统，但是磁盘阵列等技术可以将一个分区格式化为多个文件系统。 组成最主要的几个组成部分如下： inode：一个文件占用一个 inode，记录文件的属性，同时记录此文件的内容所在的 block 编号； block：记录文件的内容，文件太大时，会占用多个 block。 除此之外还包括： superblock：记录文件系统的整体信息，包括 inode 和 block 的总量、使用量、剩余量，以及文件系统的格式与相关信息等； block bitmap：记录 block 是否被使用的位图。 文件读取对于 Ext2 文件系统，当要读取一个文件的内容时，先在 inode 中查找文件内容所在的所有 block，然后把所有 block 的内容读出来。 而对于 FAT 文件系统，它没有 inode，每个 block 中存储着下一个 block 的编号。 磁盘碎片指一个文件内容所在的 block 过于分散，导致磁盘磁头移动距离过大，从而降低磁盘读写性能。 block在 Ext2 文件系统中所支持的 block 大小有 1K，2K 及 4K 三种，不同的大小限制了单个文件和文件系统的最大大小。 大小 1KB 2KB 4KB 最大单一文件 16GB 256GB 2TB 最大文件系统 2TB 8TB 16TB 一个 block 只能被一个文件所使用，未使用的部分直接浪费了。因此如果需要存储大量的小文件，那么最好选用比较小的 block。 inodeinode 具体包含以下信息： 权限 (read/write/excute)； 拥有者与群组 (owner/group)； 容量； 建立或状态改变的时间 (ctime)； 最近读取时间 (atime)； 最近修改时间 (mtime)； 定义文件特性的旗标 (flag)，如 SetUID…； 该文件真正内容的指向 (pointer)。 inode 具有以下特点： 每个 inode 大小均固定为 128 bytes (新的 ext4 与 xfs 可设定到 256 bytes)； 每个文件都仅会占用一个 inode。 inode 中记录了文件内容所在的 block 编号，但是每个 block 非常小，一个大文件随便都需要几十万的 block。而一个 inode 大小有限，无法直接引用这么多 block 编号。因此引入了间接、双间接、三间接引用。间接引用让 inode 记录的引用 block 块记录引用信息。 目录建立一个目录时，会分配一个 inode 与至少一个 block。block 记录的内容是目录下所有文件的 inode 编号以及文件名。 可以看到文件的 inode 本身不记录文件名，文件名记录在目录中，因此新增文件、删除文件、更改文件名这些操作与目录的写权限有关。 日志如果突然断电，那么文件系统会发生错误，例如断电前只修改了 block bitmap，而还没有将数据真正写入 block 中。 ext3/ext4 文件系统引入了日志功能，可以利用日志来修复文件系统。 挂载挂载利用目录作为文件系统的进入点，也就是说，进入目录之后就可以读取文件系统的数据。 目录配置为了使不同 Linux 发行版本的目录结构保持一致性，Filesystem Hierarchy Standard (FHS) 规定了 Linux 的目录结构。最基础的三个目录如下： / (root, 根目录) /usr (unix software resource)：所有系统默认软件都会安装到这个目录； /var (variable)：存放系统或程序运行过程中的数据文件。 五、文件文件属性用户分为三种：文件拥有者、群组以及其它人，对不同的用户有不同的文件权限。 使用 ls 查看一个文件时，会显示一个文件的信息，例如 drwxr-xr-x 3 root root 17 May 6 00:14 .config，对这个信息的解释如下： drwxr-xr-x：文件类型以及权限，第 1 位为文件类型字段，后 9 位为文件权限字段 3：链接数 root：文件拥有者 root：所属群组 17：文件大小 May 6 00:14：文件最后被修改的时间 .config：文件名 常见的文件类型及其含义有： d：目录 -：文件 l：链接文件 9 位的文件权限字段中，每 3 个为一组，共 3 组，每一组分别代表对文件拥有者、所属群组以及其它人的文件权限。一组权限中的 3 位分别为 r、w、x 权限，表示可读、可写、可执行。 文件时间有以下三种： modification time (mtime)：文件的内容更新就会更新； status time (ctime)：文件的状态（权限、属性）更新就会更新； access time (atime)：读取文件时就会更新。 文件与目录的基本操作1. ls列出文件或者目录的信息，目录的信息就是其中包含的文件。 1234# ls [-aAdfFhilnrRSt] file|dir-a ：列出全部的文件-d ：仅列出目录本身-l ：以长数据串行列出，包含文件的属性与权限等等数据 2. cd更换当前目录。 1cd [相对路径或绝对路径] 3. mkdir创建目录。 123# mkdir [-mp] 目录名称-m ：配置目录权限-p ：递归创建目录 4. rmdir删除目录，目录必须为空。 12rmdir [-p] 目录名称-p ：递归删除目录 5. touch更新文件时间或者建立新文件。 123456# touch [-acdmt] filename-a ： 更新 atime-c ： 更新 ctime，若该文件不存在则不建立新文件-m ： 更新 mtime-d ： 后面可以接更新日期而不使用当前日期，也可以使用 --date="日期或时间"-t ： 后面可以接更新时间而不使用当前时间，格式为[YYYYMMDDhhmm] 6. cp复制文件。如果源文件有两个以上，则目的文件一定要是目录才行。 12345678cp [-adfilprsu] source destination-a ：相当于 -dr --preserve=all-d ：若来源文件为链接文件，则复制链接文件属性而非文件本身-i ：若目标文件已经存在时，在覆盖前会先询问-p ：连同文件的属性一起复制过去-r ：递归复制-u ：destination 比 source 旧才更新 destination，或 destination 不存在的情况下才复制--preserve=all ：除了 -p 的权限相关参数外，还加入 SELinux 的属性, links, xattr 等也复制了 7. rm删除文件。 12# rm [-fir] 文件或目录-r ：递归删除 8. mv移动文件。 123# mv [-fiu] source destination# mv [options] source1 source2 source3 .... directory-f ： force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 修改权限可以将一组权限用数字来表示，此时一组权限的 3 个位当做二进制数字的位，从左到右每个位的权值为 4、2、1，即每个权限对应的数字权值为 r : 4、w : 2、x : 1。 1# chmod [-R] xyz dirname/filename 示例：将 .bashrc 文件的权限修改为 -rwxr-xr–。 1# chmod 754 .bashrc 也可以使用符号来设定权限。 12345678# chmod [ugoa] [+-=] [rwx] dirname/filename- u：拥有者- g：所属群组- o：其他人- a：所有人- +：添加权限- -：移除权限- =：设定权限 示例：为 .bashrc 文件的所有用户添加写权限。 1# chmod a+w .bashrc 默认权限 文件默认权限：文件默认没有可执行权限，因此为 666，也就是 -rw-rw-rw- 。 目录默认权限：目录必须要能够进入，也就是必须拥有可执行权限，因此为 777 ，也就是 drwxrwxrwx。 可以通过 umask 设置或者查看默认权限，通常以掩码的形式来表示，例如 002 表示其它用户的权限去除了一个 2 的权限，也就是写权限，因此建立新文件时默认的权限为 -rw-rw-r–。 目录的权限文件名不是存储在一个文件的内容中，而是存储在一个文件所在的目录中。因此，拥有文件的 w 权限并不能对文件名进行修改。 目录存储文件列表，一个目录的权限也就是对其文件列表的权限。因此，目录的 r 权限表示可以读取文件列表；w 权限表示可以修改文件列表，具体来说，就是添加删除文件，对文件名进行修改；x 权限可以让该目录成为工作目录，x 权限是 r 和 w 权限的基础，如果不能使一个目录成为工作目录，也就没办法读取文件列表以及对文件列表进行修改了。 链接 123# ln [-sf] source_filename dist_filename-s ：默认是实体链接，加 -s 为符号链接-f ：如果目标文件存在时，先删除目标文件 1. 实体链接在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。 删除任意一个条目，文件还是存在，只要引用数量不为 0。 有以下限制：不能跨越文件系统、不能对目录进行链接。 1234# ln /etc/crontab .# ll -i /etc/crontab crontab34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 crontab34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab 2. 符号链接符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。 当源文件被删除了，链接文件就打不开了。 因为记录的是路径，所以可以为目录建立符号链接。 123# ll -i /etc/crontab /root/crontab234474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab53745909 lrwxrwxrwx. 1 root root 12 Jun 23 22:31 /root/crontab2 -&gt; /etc/crontab 获取文件内容1. cat取得文件内容。 12# cat [-AbEnTv] filename-n ：打印出行号，连同空白行也会有行号，-b 不会 2. tac是 cat 的反向操作，从最后一行开始打印。 3. more和 cat 不同的是它可以一页一页查看文件内容，比较适合大文件的查看。 4. less和 more 类似，但是多了一个向前翻页的功能。 5. head取得文件前几行。 12# head [-n number] filename-n ：后面接数字，代表显示几行的意思 6. tail是 head 的反向操作，只是取得是后几行。 7. od以字符或者十六进制的形式显示二进制文件。 指令与文件搜索1. which指令搜索。 12# which [-a] command-a ：将所有指令列出，而不是只列第一个 2. whereis文件搜索。速度比较快，因为它只搜索几个特定的目录。 1# whereis [-bmsu] dirname/filename 3. locate文件搜索。可以用关键字或者正则表达式进行搜索。 locate 使用 /var/lib/mlocate/ 这个数据库来进行搜索，它存储在内存中，并且每天更新一次，所以无法用 locate 搜索新建的文件。可以使用 updatedb 来立即更新数据库。 12# locate [-ir] keyword-r：正则表达式 4. find文件搜索。可以使用文件的属性和权限进行搜索。 12# find [basedir] [option]example: find . -name "shadow*" ① 与时间有关的选项 1234-mtime n ：列出在 n 天前的那一天修改过内容的文件-mtime +n ：列出在 n 天之前 (不含 n 天本身) 修改过内容的文件-mtime -n ：列出在 n 天之内 (含 n 天本身) 修改过内容的文件-newer file ： 列出比 file 更新的文件 +4、4 和 -4 的指示的时间范围如下： ② 与文件拥有者和所属群组有关的选项 123456-uid n-gid n-user name-group name-nouser ：搜索拥有者不存在 /etc/passwd 的文件-nogroup：搜索所属群组不存在于 /etc/group 的文件 ③ 与文件权限和名称有关的选项 123456-name filename-size [+-]SIZE：搜寻比 SIZE 还要大 (+) 或小 (-) 的文件。这个 SIZE 的规格有：c: 代表 byte，k: 代表 1024bytes。所以，要找比 50KB 还要大的文件，就是 -size +50k-type TYPE-perm mode ：搜索权限等于 mode 的文件-perm -mode ：搜索权限包含 mode 的文件-perm /mode ：搜索权限包含任一 mode 的文件 六、压缩与打包压缩文件名Linux 底下有很多压缩文件名，常见的如下： 扩展名 压缩程序 *.Z compress *.zip zip *.gz gzip *.bz2 bzip2 *.xz xz *.tar tar 程序打包的数据，没有经过压缩 *.tar.gz tar 程序打包的文件，经过 gzip 的压缩 *.tar.bz2 tar 程序打包的文件，经过 bzip2 的压缩 *.tar.xz tar 程序打包的文件，经过 xz 的压缩 压缩指令1. gzipgzip 是 Linux 使用最广的压缩指令，可以解开 compress、zip 与 gzip 所压缩的文件。 经过 gzip 压缩过，源文件就不存在了。 有 9 个不同的压缩等级可以使用。 可以使用 zcat、zmore、zless 来读取压缩文件的内容。 123456$ gzip [-cdtv#] filename-c ：将压缩的数据输出到屏幕上-d ：解压缩-t ：检验压缩文件是否出错-v ：显示压缩比等信息-# ： # 为数字的意思，代表压缩等级，数字越大压缩比越高，默认为 6 2. bzip2提供比 gzip 更高的压缩比。 查看命令：bzcat、bzmore、bzless、bzgrep。 12$ bzip2 [-cdkzv#] filename-k ：保留源文件 3. xz提供比 bzip2 更佳的压缩比。 可以看到，gzip、bzip2、xz 的压缩比不断优化。不过要注意的是，压缩比越高，压缩的时间也越长。 查看命令：xzcat、xzmore、xzless、xzgrep。 1$ xz [-dtlkc#] filename 打包压缩指令只能对一个文件进行压缩，而打包能够将多个文件打包成一个大文件。tar 不仅可以用于打包，也可以使用 gzip、bzip2、xz 将打包文件进行压缩。 123456789101112$ tar [-z|-j|-J] [cv] [-f 新建的 tar 文件] filename... ==打包压缩$ tar [-z|-j|-J] [tv] [-f 已有的 tar 文件] ==查看$ tar [-z|-j|-J] [xv] [-f 已有的 tar 文件] [-C 目录] ==解压缩-z ：使用 zip；-j ：使用 bzip2；-J ：使用 xz；-c ：新建打包文件；-t ：查看打包文件里面有哪些文件；-x ：解打包或解压缩的功能；-v ：在压缩/解压缩的过程中，显示正在处理的文件名；-f : filename：要处理的文件；-C 目录 ： 在特定目录解压缩。 使用方式 命令 打包压缩 tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称 查 看 tar -jtv -f filename.tar.bz2 解压缩 tar -jxv -f filename.tar.bz2 -C 要解压缩的目录 七、Bash可以通过 Shell 请求内核提供服务，Bash 正是 Shell 的一种。 特性 命令历史：记录使用过的命令 命令与文件补全：快捷键：tab 命名别名：例如 ll 是 ls -al 的别名 shell scripts 通配符：例如 ls -l /usr/bin/X* 列出 /usr/bin 下面所有以 X 开头的文件 变量操作对一个变量赋值直接使用 =。 对变量取用需要在变量前加上 $ ，也可以用 ${} 的形式； 输出变量使用 echo 命令。 123$ x=abc$ echo $x$ echo $&#123;x&#125; 变量内容如果有空格，必须使用双引号或者单引号。 双引号内的特殊字符可以保留原本特性，例如 x=”lang is $LANG”，则 x 的值为 lang is zh_TW.UTF-8； 单引号内的特殊字符就是特殊字符本身，例如 x=’lang is $LANG’，则 x 的值为 lang is $LANG。 可以使用 `指令` 或者 $(指令) 的方式将指令的执行结果赋值给变量。例如 version=$(uname -r)，则 version 的值为 4.15.0-22-generic。 可以使用 export 命令将自定义变量转成环境变量，环境变量可以在子程序中使用，所谓子程序就是由当前 Bash 而产生的子 Bash。 Bash 的变量可以声明为数组和整数数字。注意数字类型没有浮点数。如果不进行声明，默认是字符串类型。变量的声明使用 declare 命令： 12345$ declare [-aixr] variable-a ： 定义为数组类型-i ： 定义为整数类型-x ： 定义为环境变量-r ： 定义为 readonly 类型 使用 [ ] 来对数组进行索引操作： 123$ array[1]=a$ array[2]=b$ echo $&#123;array[1]&#125; 指令搜索顺序 以绝对或相对路径来执行指令，例如 /bin/ls 或者 ./ls ； 由别名找到该指令来执行； 由 Bash 内置的指令来执行； 按 $PATH 变量指定的搜索路径的顺序找到第一个指令来执行。 数据流重定向重定向指的是使用文件代替标准输入、标准输出和标准错误输出。 1 代码 运算符 标准输入 (stdin) 0 &lt; 或 &lt;&lt; 标准输出 (stdout) 1 &gt; 或 &gt;&gt; 标准错误输出 (stderr) 2 2&gt; 或 2&gt;&gt; 其中，有一个箭头的表示以覆盖的方式重定向，而有两个箭头的表示以追加的方式重定向。 可以将不需要的标准输出以及标准错误输出重定向到 /dev/null，相当于扔进垃圾箱。 如果需要将标准输出以及标准错误输出同时重定向到一个文件，需要将某个输出转换为另一个输出，例如 2&gt;&amp;1 表示将标准错误输出转换为标准输出。 1$ find /home -name .bashrc &gt; list 2&gt;&amp;1 八、管道指令管道是将一个命令的标准输出作为另一个命令的标准输入，在数据需要经过多个步骤的处理之后才能得到我们想要的内容时就可以使用管道。 在命令之间使用 | 分隔各个管道命令。 1$ ls -al /etc | less 提取指令cut 对数据进行切分，取出想要的部分。 切分过程一行一行地进行。 1234$ cut-d ：分隔符-f ：经过 -d 分隔后，使用 -f n 取出第 n 个区间-c ：以字符为单位取出区间 示例 1：last 显示登入者的信息，取出用户名。 123456$ lastroot pts/1 192.168.201.101 Sat Feb 7 12:35 still logged inroot pts/1 192.168.201.101 Fri Feb 6 12:13 - 18:46 (06:33)root pts/1 192.168.201.254 Thu Feb 5 22:37 - 23:53 (01:16)$ last | cut -d ' ' -f 1 示例 2：将 export 输出的信息，取出第 12 字符以后的所有字符串。 12345678$ exportdeclare -x HISTCONTROL="ignoredups"declare -x HISTSIZE="1000"declare -x HOME="/home/dmtsai"declare -x HOSTNAME="study.centos.vbird".....(其他省略).....$ export | cut -c 12- 排序指令sort 用于排序。 123456789$ sort [-fbMnrtuk] [file or stdin]-f ：忽略大小写-b ：忽略最前面的空格-M ：以月份的名字来排序，例如 JAN，DEC-n ：使用数字-r ：反向排序-u ：相当于 unique，重复的内容只出现一次-t ：分隔符，默认为 tab-k ：指定排序的区间 示例：/etc/passwd 文件内容以 : 来分隔，要求以第三列进行排序。 12345$ cat /etc/passwd | sort -t ':' -k 3root:x:0:0:root:/root:/bin/bashdmtsai:x:1000:1000:dmtsai:/home/dmtsai:/bin/bashalex:x:1001:1002::/home/alex:/bin/basharod:x:1002:1003::/home/arod:/bin/bash uniq 可以将重复的数据只取一个。 123$ uniq [-ic]-i ：忽略大小写-c ：进行计数 示例：取得每个人的登录总次数 1234567$ last | cut -d ' ' -f 1 | sort | uniq -c16 (unknown47 dmtsai4 reboot7 root1 wtmp 双向输出重定向输出重定向会将输出内容重定向到文件中，而 tee 不仅能够完成这个功能，还能保留屏幕上的输出。也就是说，使用 tee 指令，一个输出会同时传送到文件和屏幕上。 1$ tee [-a] file 字符转换指令tr 用来删除一行中的字符，或者对字符进行替换。 12$ tr [-ds] SET1 ...-d ： 删除行中 SET1 这个字符串 示例，将 last 输出的信息所有小写转换为大写。 1$ last | tr '[a-z]' '[A-Z]' col 将 tab 字符转为空格字符。 12$ col [-xb]-x ： 将 tab 键转换成对等的空格键 expand 将 tab 转换一定数量的空格，默认是 8 个。 12$ expand [-t] file-t ：tab 转为空格的数量 join 将有相同数据的那一行合并在一起。 12345$ join [-ti12] file1 file2-t ：分隔符，默认为空格-i ：忽略大小写的差异-1 ：第一个文件所用的比较字段-2 ：第二个文件所用的比较字段 paste 直接将两行粘贴在一起。 12$ paste [-d] file1 file2-d ：分隔符，默认为 tab 分区指令split 将一个文件划分成多个文件。 1234$ split [-bl] file PREFIX-b ：以大小来进行分区，可加单位，例如 b, k, m 等-l ：以行数来进行分区。- PREFIX ：分区文件的前导名称 九、正则表达式grepg/re/p（globally search a regular expression and print)，使用正则表示式进行全局查找并打印。 123456$ grep [-acinv] [--color=auto] 搜寻字符串 filename-c ： 统计个数-i ： 忽略大小写-n ： 输出行号-v ： 反向选择，也就是显示出没有 搜寻字符串 内容的那一行--color=auto ：找到的关键字加颜色显示 示例：把含有 the 字符串的行提取出来（注意默认会有 –color=auto 选项，因此以下内容在 Linux 中有颜色显示 the 字符串） 123456$ grep -n 'the' regular_express.txt8:I can't finish the test.12:the symbol '*' is represented as start.15:You are the best is mean you are the no. 1.16:The world Happy is the same with "glad".18:google is the best tools for search keyword 因为 { 和 } 在 shell 是有特殊意义的，因此必须要使用转义字符进行转义。 1$ grep -n 'go\&#123;2,5\&#125;g' regular_express.txt printf用于格式化输出。它不属于管道命令，在给 printf 传数据时需要使用 $( ) 形式。 1234$ printf '%10s %5i %5i %5i %8.2f \n' $(cat printf.txt) DmTsai 80 60 92 77.33 VBird 75 55 80 70.00 Ken 60 90 70 73.33 awk是由 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 创造，awk 这个名字就是这三个创始人名字的首字母。 awk 每次处理一行，处理的最小单位是字段，每个字段的命名方式为：$n，n 为字段号，从 1 开始，$0 表示一整行。 示例：取出最近五个登录用户的用户名和 IP 123456$ last -n 5dmtsai pts/0 192.168.1.100 Tue Jul 14 17:32 still logged indmtsai pts/0 192.168.1.100 Thu Jul 9 23:36 - 02:58 (03:22)dmtsai pts/0 192.168.1.100 Thu Jul 9 17:23 - 23:36 (06:12)dmtsai pts/0 192.168.1.100 Thu Jul 9 08:02 - 08:17 (00:14)dmtsai tty1 Fri May 29 11:55 - 12:11 (00:15) 1$ last -n 5 | awk '&#123;print $1 "\t" $3&#125;' 可以根据字段的某些条件进行匹配，例如匹配字段小于某个值的那一行数据。 1$ awk '条件类型 1 &#123;动作 1&#125; 条件类型 2 &#123;动作 2&#125; ...' filename 示例：/etc/passwd 文件第三个字段为 UID，对 UID 小于 10 的数据进行处理。 1234$ cat /etc/passwd | awk &apos;BEGIN &#123;FS=&quot;:&quot;&#125; $3 &lt; 10 &#123;print $1 &quot;\t &quot; $3&#125;&apos;root 0bin 1daemon 2 awk 变量： 变量名称 代表意义 NF 每一行拥有的字段总数 NR 目前所处理的是第几行数据 FS 目前的分隔字符，默认是空格键 示例：显示正在处理的行号以及每一行有多少字段 123456$ last -n 5 | awk '&#123;print $1 "\t lines: " NR "\t columns: " NF&#125;'dmtsai lines: 1 columns: 10dmtsai lines: 2 columns: 10dmtsai lines: 3 columns: 10dmtsai lines: 4 columns: 10dmtsai lines: 5 columns: 9 十、进程管理查看进程1. ps查看某个时间点的进程信息。 示例一：查看自己的进程 1# ps -l 示例二：查看系统所有进程 1# ps aux 示例三：查看特定的进程 1# ps aux | grep threadx 2. pstree查看进程树。 示例：查看所有进程树 1# pstree -A 3. top实时显示进程信息。 示例：两秒钟刷新一次 1# top -d 2 4. netstat查看占用端口的进程 示例：查看特定端口的进程 1# netstat -anp | grep port 进程状态 状态 说明 R running or runnable (on run queue)正在执行或者可执行，此时进程位于执行队列中。 D uninterruptible sleep (usually I/O)不可中断阻塞，通常为 IO 阻塞。 S interruptible sleep (waiting for an event to complete) 可中断阻塞，此时进程正在等待某个事件完成。 Z zombie (terminated but not reaped by its parent)僵死，进程已经终止但是尚未被其父进程获取信息。 T stopped (either by a job control signal or because it is being traced) 结束，进程既可以被作业控制信号结束，也可能是正在被追踪。 SIGCHLD当一个子进程改变了它的状态时（停止运行，继续运行或者退出），有两件事会发生在父进程中： 得到 SIGCHLD 信号； waitpid() 或者 wait() 调用会返回。 其中子进程发送的 SIGCHLD 信号包含了子进程的信息，比如进程 ID、进程状态、进程使用 CPU 的时间等。 在子进程退出时，它的进程描述符不会立即释放，这是为了让父进程得到子进程信息，父进程通过 wait() 和 waitpid() 来获得一个已经退出的子进程的信息。 wait()1pid_t wait(int *status) 父进程调用 wait() 会一直阻塞，直到收到一个子进程退出的 SIGCHLD 信号，之后 wait() 函数会销毁子进程并返回。 如果成功，返回被收集的子进程的进程 ID；如果调用进程没有子进程，调用就会失败，此时返回 -1，同时 errno 被置为 ECHILD。 参数 status 用来保存被收集的子进程退出时的一些状态，如果对这个子进程是如何死掉的毫不在意，只想把这个子进程消灭掉，可以设置这个参数为 NULL。 waitpid()1pid_t waitpid(pid_t pid, int *status, int options) 作用和 wait() 完全相同，但是多了两个可由用户控制的参数 pid 和 options。 pid 参数指示一个子进程的 ID，表示只关心这个子进程退出的 SIGCHLD 信号。如果 pid=-1 时，那么和 wait() 作用相同，都是关心所有子进程退出的 SIGCHLD 信号。 options 参数主要有 WNOHANG 和 WUNTRACED 两个选项，WNOHANG 可以使 waitpid() 调用变成非阻塞的，也就是说它会立即返回，父进程可以继续执行其它任务。 孤儿进程一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。 孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作。 由于孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。 僵尸进程一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。 僵尸进程通过 ps 命令显示出来的状态为 Z（zombie）。 系统所能使用的进程号是有限的，如果产生大量僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。 要消灭系统中大量的僵尸进程，只需要将其父进程杀死，此时僵尸进程就会变成孤儿进程，从而被 init 进程所收养，这样 init 进程就会释放所有的僵尸进程所占有的资源，从而结束僵尸进程。 参考资料 鸟哥. 鸟 哥 的 Linux 私 房 菜 基 础 篇 第 三 版[J]. 2009. https://cyc2018.github.io/CS-Notes/#/notes/Linux]]></content>
      <categories>
        <category>操作系统</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统-进程管理]]></title>
    <url>%2F2019%2F03%2F20%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[进程与线程1. 进程进程是资源分配的基本单位。 进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。 下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。 解答：D。程序一开始，产生一个进程Pl执行此程序，P1进入程序后，此时i=0，于是进入循环体，fork()产生一个子进程P2，接着Pl执行下一条语句输出一个”-“（其实是放入缓冲区，等合适的时候再输出，我们将此’-‘记为a）； P2成为一个独立的子进程，继承P1的诸如环境变量、PC等环境，P2也执行下一条语句输出一个’-‘（其实是放入缓冲区，等合适的时候再输出，我们将此记为b），同时P2中此时i=1，继续执行for 循环P2先forkO出一个子进程P3，然后P2再执行下一条语句输出一个一（其实是放入缓冲区，等合适的时候再输出，我们将此记为c）。 P3进程为P2的子进程，它会复制其父进程P2的诸如环境变量、PC等环境，它执行下一条语句（输出语句）本应该输出一个，但事实上因为这里P3会继承P2的缓冲区，而P2的缓冲区中有一个（P2调用fork产生P3时缓冲区里有b），所以P3会输出两个。 Pl产生子进程P2后，继续下一轮循环，当i=1时，fork()产生另一个它的子进程P4，同时P1执行输出语句输出一个’-‘。 2. 线程线程是独立调度的基本单位。 一个进程中可以有多个线程，它们共享进程资源。 QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。 例1：同一进程下的线程可以共享（）。（2012·搜狗） A.stack B.data section C.register set D.thread ID 解答：B。B中data section存放全局变量等内容，显然是可以被同一进程下的线程共享的。 例2：线程与进程比较而言，下面论述成立的有（）。（不定项选择）（2007·百度） A.一个线程可以由多个进程组成 B.一个进程可以由多个线程组成 C.相对而言，线程运行需要更多的资源 D.线程比进程运行需要更少的系统资源 解答：BD。 例3：进程和线程的差别有（）。（2010·网易） A.操作系统只调度进程，不调度线程 B.线程共享内存地址空间，进程不共享C.线程可以共享内存数据，但进程不可以 D.进程间可以通过IPC通信，但线程不可以 解答：B。进程之间的地址空间是独享的，而线程共享进程的地址空间。 例4：两个线程： 12345threadl:x=1； r1=y； thread2：y=1； r2=x； x和y初始值为0，两者皆为全局变量，程序运行过后r1和r2的值可能是（）。（2012·微软） A.rl=1，r2=1 B.rl=1，r2=0 C.rl=0，r2=1 D.rl=0，r2=0 解答：ABC。 首先执行x=1，然后中断，执行y=1，r2=x，然后执行rl=y，可得r1=1，r2=1； 首先执行thread1，再执行thread2，可得r1=0，r2=1； 首先执行thread2，再执行thread1，可得r1=1，r2=0。 引入线程主要有以下4个优点： （1）易于调度。 （2）提高并发性。 （3）开销小。 （4）有利于发挥多处理器的功能。 3. 区别Ⅰ 拥有资源 进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。 Ⅱ 调度 线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。 Ⅲ 系统开销 由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。 Ⅳ 通信方面 线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。 进程状态的切换 就绪状态（ready）：等待被调度 运行状态（running） 阻塞状态（waiting）：等待资源 应该注意以下内容： 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。 进程调度算法不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。 1. 批处理系统批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。 1.1 先来先服务 first-come first-serverd（FCFS） 非抢占式的调度算法，按照请求的顺序进行调度。 有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。 1.2 短作业优先 shortest job first（SJF） 非抢占式的调度算法，按估计运行时间最短的顺序进行调度。 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。 1.3 最短剩余时间优先 shortest remaining time next（SRTN） 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。 2. 交互式系统交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。 2.1 时间片轮转 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 时间片轮转算法的效率和时间片的大小有很大关系： 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。 2.2 优先级调度 为每个进程分配一个优先级，按优先级进行调度。 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 2.3 多级反馈队列 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。 多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。 每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。 可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。 3. 实时系统实时系统要求一个请求在一个确定时间内得到响应。 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。 4.练习例1：一种既有利于短作业又兼顾长作业的调度方式是（）。（2012·搜狗） A.先来先服务 B.均衡调度 C.最短作业优先 D.最高响应比优先 解答：D。 例2：假定我们有3个程序，每个程序花费80%的时间进行I/0，20%的时间使用CPU。每个程序启动时间和其需要使用进行计算的分钟数如下，不考虑进程切换时间： 请问，在多线程/进程环境下，系统的总周转时间为（）。（2012·腾讯） A.22.5 B.23.5 C.24.5 D.25.5 解答：B。从0点0分开始到0点10分，系统里只有1个程序，因此属于单道编程状态。单道编程时CPU的利用率为20%，因此第1个程序在该10分钟里总共使用了CPU达2分钟（其他8分钟都用来进行I/0了）。0点10分到0点15分，系统里面有两个程序，因此属于2道编程。2道编程时CPU利用率为36%（两个进程同时不使用CPU的概率是0.8*0.8-0.64），则在5分钟时间内，CPU使用了1.8分钟。假定这两个程序完全平等，则每个程序使用CPU的时间是0.9分钟。至此，程序1总共运行了2.9分钟CPU时间，程序2运行了0.9分钟CPU时间。 从0点15分开始，系统里面有3个程序，因此属于3道编程状态。3道编程时CPU的利用率为48.8%（三个进程同时不使用CPU的概率是0.80.80.8=0.512），同样，假定所有程序完全平等，此时，程序1离结束所需要的CPU时间最短，仅为0.6分钟。而如果程序1想再运行0.6分钟CPU时间，则整个系统需运行时间约为3.7分钟（3.7分钟时间内CPU共被使用1.8分钟，平均每个程序使用CPU时间为0.6分钟），因此在0点18.7分时，第一个程序执行完毕，系统变为2道编程。 2道编程时CPU利用率为36%，此时程序2运行了0.9+0.6-1.5分钟，程序3运行了0.6分钟，此时，程序2离结束所需要的CPU时间最短，仅为0.5分钟。而如果程序2想再运行0.5分钟CPU时间，则整个系统需运行时间约为2.8分钟（2.8分钟时间内CPU共被使用1分钟，平均每个程序使用CPU时间为0.5分钟），因此在0点21.5分时，第二个程序执行完毕，系统变为1道编程。 系统里只有1个程序，因此属于单道编程状态。单道编程时CPU的利用率为20%，此时程序3运行了0.6+0.5=1.1分钟，还需要运行0.4分钟的CPU时间，故整个系统需要2分钟（2分钟内CPU被利用0.4分钟），故程序3在0点23.5分时结束。 进程同步1. 临界区对临界资源进行访问的那段代码称为临界区。 为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。 123// entry section// critical section;// exit section 2. 同步与互斥 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。 互斥：多个进程在同一时刻只有一个进程能进入临界区。 3. 信号量信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。 down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0； up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。 down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。 如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。 12345678910111213typedef int semaphore;semaphore mutex = 1;void P1() &#123; down(&amp;mutex); // 临界区 up(&amp;mutex);&#125;void P2() &#123; down(&amp;mutex); // 临界区 up(&amp;mutex);&#125; 使用信号量实现生产者-消费者问题 问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。 因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。 为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。 注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。 123456789101112131415161718192021222324252627#define N 100typedef int semaphore;semaphore mutex = 1;semaphore empty = N;semaphore full = 0;void producer() &#123; while(TRUE) &#123; int item = produce_item(); down(&amp;empty); down(&amp;mutex); insert_item(item); up(&amp;mutex); up(&amp;full); &#125;&#125;void consumer() &#123; while(TRUE) &#123; down(&amp;full); down(&amp;mutex); int item = remove_item(); consume_item(item); up(&amp;mutex); up(&amp;empty); &#125;&#125; 4. 管程使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。 c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。 1234567891011121314monitor ProducerConsumer integer i; condition c; procedure insert(); begin // ... end; procedure remove(); begin // ... end;end monitor; 管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。 管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。 使用管程实现生产者-消费者问题 123456789101112131415161718192021222324252627282930313233343536373839404142// 管程monitor ProducerConsumer condition full, empty; integer count := 0; condition c; procedure insert(item: integer); begin if count = N then wait(full); insert_item(item); count := count + 1; if count = 1 then signal(empty); end; function remove: integer; begin if count = 0 then wait(empty); remove = remove_item; count := count - 1; if count = N -1 then signal(full); end;end monitor;// 生产者客户端procedure producerbegin while true do begin item = produce_item; ProducerConsumer.insert(item); endend;// 消费者客户端procedure consumerbegin while true do begin item = ProducerConsumer.remove; consume_item(item); endend; 经典同步问题生产者和消费者问题前面已经讨论过了。 1. 读者-写者问题允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。 一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。 1234567891011121314151617181920212223242526typedef int semaphore;semaphore count_mutex = 1;semaphore data_mutex = 1;int count = 0;void reader() &#123; while(TRUE) &#123; down(&amp;count_mutex); count++; if(count == 1) down(&amp;data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问 up(&amp;count_mutex); read(); down(&amp;count_mutex); count--; if(count == 0) up(&amp;data_mutex); up(&amp;count_mutex); &#125;&#125;void writer() &#123; while(TRUE) &#123; down(&amp;data_mutex); write(); up(&amp;data_mutex); &#125;&#125; 2. 哲学家进餐问题 五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。 下面是一种错误的解法，考虑到如果所有哲学家同时拿起左手边的筷子，那么就无法拿起右手边的筷子，造成死锁。 123456789101112#define N 5void philosopher(int i) &#123; while(TRUE) &#123; think(); take(i); // 拿起左边的筷子 take((i+1)%N); // 拿起右边的筷子 eat(); put(i); put((i+1)%N); &#125;&#125; 为了防止死锁的发生，可以设置两个条件： 必须同时拿起左右两根筷子； 只有在两个邻居都没有进餐的情况下才允许进餐。 123456789101112131415161718192021222324252627282930313233343536373839404142#define N 5#define LEFT (i + N - 1) % N // 左邻居#define RIGHT (i + 1) % N // 右邻居#define THINKING 0#define HUNGRY 1#define EATING 2typedef int semaphore;int state[N]; // 跟踪每个哲学家的状态semaphore mutex = 1; // 临界区的互斥semaphore s[N]; // 每个哲学家一个信号量void philosopher(int i) &#123; while(TRUE) &#123; think(); take_two(i); eat(); put_two(i); &#125;&#125;void take_two(int i) &#123; down(&amp;mutex); state[i] = HUNGRY; test(i); up(&amp;mutex); down(&amp;s[i]);&#125;void put_two(i) &#123; down(&amp;mutex); state[i] = THINKING; test(LEFT); test(RIGHT); up(&amp;mutex);&#125;void test(i) &#123; // 尝试拿起两把筷子 if(state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] !=EATING) &#123; state[i] = EATING; up(&amp;s[i]); &#125;&#125; 进程通信进程同步与进程通信很容易混淆，它们的区别在于： 进程同步：控制多个进程按一定顺序执行； 进程通信：进程间传输信息。 进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。 1. 管道管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。 12#include &lt;unistd.h&gt;int pipe(int fd[2]); 它具有以下限制： 只支持半双工通信（单向交替传输）； 只能在父子进程或者兄弟进程中使用。 2. FIFO也称为命名管道，去除了管道只能在父子进程中使用的限制。 123#include &lt;sys/stat.h&gt;int mkfifo(const char *path, mode_t mode);int mkfifoat(int fd, const char *path, mode_t mode); FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。 3. 消息队列相比于 FIFO，消息队列具有以下优点： 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难； 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法； 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。 4. 信号量它是一个计数器，用于为多个进程提供对共享数据对象的访问。 5. 共享存储允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。 需要使用信号量用来同步对共享存储的访问。 多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。 6. 套接字与其它通信机制不同的是，它可用于不同机器间的进程通信。 参考： [https://cyc2018.github.io/CS-Notes/#/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86](https://cyc2018.github.io/CS-Notes/#/notes/计算机操作系统 - 进程管理)]]></content>
      <categories>
        <category>操作系统</category>
        <category>操作系统概念</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell]]></title>
    <url>%2F2019%2F03%2F19%2FShell%2F</url>
    <content type="text"><![CDATA[Shell 编程入门什么是 Shell？简单来说“Shell编程就是对一堆Linux命令的逻辑化处理”。 W3Cschool 上的一篇文章是这样介绍 Shell的，如下图所示。 Shell 编程的 Hello World学习任何一门编程语言第一件事就是输出HelloWord了！下面我会从新建文件到shell代码编写来说下Shell 编程如何输出Hello World。 (1)新建一个文件 helloworld.sh :touch helloworld.sh，扩展名为 sh（sh代表Shell）（扩展名并不影响脚本执行，见名知意就好，如果你用 php 写 shell 脚本，扩展名就用 php 好了） (2) 使脚本具有执行权限：chmod +x helloworld.sh (3) 使用 vim 命令修改helloworld.sh文件：vim helloworld.sh(vim 文件——&gt;进入文件—–&gt;命令模式——&gt;按i进入编辑模式—–&gt;编辑文件 ——-&gt;按Esc进入底行模式—–&gt;输入:wq/q! （输入wq代表写入内容并退出，即保存；输入q!代表强制退出不保存。）) helloworld.sh 内容如下： 123#!/bin/bash#第一个shell小程序,echo 是linux中的输出命令。echo "helloworld!" shell中 # 符号表示注释。shell 的第一行比较特殊，一般都会以#!开始来指定使用的 shell 类型。在linux中，除了bash shell以外，还有很多版本的shell， 例如zsh、dash等等…不过bash shell还是我们使用最多的。 (4) 运行脚本:./helloworld.sh 。（注意，一定要写成 ./helloworld.sh ，而不是 helloworld.sh ，运行其它二进制的程序也一样，直接写 helloworld.sh ，linux 系统会去 PATH 里寻找有没有叫 test.sh 的，而只有 /bin, /sbin, /usr/bin，/usr/sbin 等在 PATH 里，你的当前目录通常不在 PATH 里，所以写成 helloworld.sh 是会找不到命令的，要用./helloworld.sh 告诉系统说，就在当前目录找。） Shell 变量Shell 编程中的变量介绍Shell编程中一般分为三种变量： 我们自己定义的变量（自定义变量）: 仅在当前 Shell 实例中有效，其他 Shell 启动的程序不能访问局部变量。 Linux已定义的环境变量（环境变量， 例如：$PATH, $HOME 等…, 这类变量我们可以直接使用），使用 env 命令可以查看所有的环境变量，而set命令既可以查看环境变量也可以查看自定义变量。 Shell变量 ：Shell变量是由 Shell 程序设置的特殊变量。Shell 变量中有一部分是环境变量，有一部分是局部变量，这些变量保证了 Shell 的正常运行 常用的环境变量: PATH 决定了shell将到哪些目录中寻找命令或程序HOME 当前用户主目录HISTSIZE 历史记录数LOGNAME 当前用户的登录名HOSTNAME 指主机的名称SHELL 当前用户Shell类型LANGUGE 语言相关的环境变量，多语言可以修改此环境变量MAIL 当前用户的邮件存放目录PS1 基本提示符，对于root用户是#，对于普通用户是$ 使用 Linux 已定义的环境变量： 比如我们要看当前用户目录可以使用：echo $HOME命令；如果我们要看当前用户Shell类型 可以使用echo $SHELL命令。可以看出，使用方法非常简单。 使用自己定义的变量： 12345#!/bin/bash#自定义变量hellohello="hello world"echo $helloecho "helloworld!" Shell 编程中的变量名的命名的注意事项： 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头，但是可以使用下划线（_）开头。 中间不能有空格，可以使用下划线（_）。 不能使用标点符号。 不能使用bash里的关键字（可用help命令查看保留关键字）。 Shell 字符串入门字符串是shell编程中最常用最有用的数据类型（除了数字和字符串，也没啥其它类型好用了），字符串可以用单引号，也可以用双引号。这点和Java中有所不同。 单引号字符串： 1234#!/bin/bashname='SnailClimb'hello='Hello, I am '$name'!'echo $hello 输出内容： 1Hello, I am SnailClimb! 双引号字符串： 1234#!/bin/bashname='SnailClimb'hello="Hello, I am "$name"!"echo $hello 输出内容： 1Hello, I am SnailClimb! Shell 字符串常见操作拼接字符串： 12345678910#!/bin/bashname="SnailClimb"# 使用双引号拼接greeting="hello, "$name" !"greeting_1="hello, $&#123;name&#125; !"echo $greeting $greeting_1# 使用单引号拼接greeting_2='hello, '$name' !'greeting_3='hello, $&#123;name&#125; !'echo $greeting_2 $greeting_3 输出结果： 获取字符串长度： 1234567#!/bin/bash#获取字符串长度name="SnailClimb"# 第一种方式echo $&#123;#name&#125; #输出 10# 第二种方式expr length "$name"; 输出结果: 121010 使用 expr 命令时，表达式中的运算符左右必须包含空格，如果不包含空格，将会输出表达式本身: 12expr 5+6 // 直接输出 5+6expr 5 + 6 // 输出 11 对于某些运算符，还需要我们使用符号\进行转义，否则就会提示语法错误。 12expr 5 * 6 // 输出错误expr 5 \* 6 // 输出30 截取子字符串: 简单的字符串截取： 123#从字符串第 1 个字符开始往后截取 10 个字符str="SnailClimb is a great man"echo $&#123;str:0:10&#125; #输出:SnailClimb 根据表达式截取： 12345678910#!bin/bash#author:amauvar="http://www.runoob.com/linux/linux-shell-variable.html"s1=$&#123;var%%t*&#125;#hs2=$&#123;var%t*&#125;#http://www.runoob.com/linux/linux-shell-variable.hs3=$&#123;var%%.*&#125;#http://wwws4=$&#123;var#*/&#125;#/www.runoob.com/linux/linux-shell-variable.htmls5=$&#123;var##*/&#125;#linux-shell-variable.html Shell 数组bash支持一维数组（不支持多维数组），并且没有限定数组的大小。我下面给了大家一个关于数组操作的 Shell 代码示例，通过该示例大家可以知道如何创建数组、获取数组长度、获取/删除特定位置的数组元素、删除整个数组以及遍历数组。 123456789101112131415#!/bin/basharray=(1 2 3 4 5);# 获取数组长度length=$&#123;#array[@]&#125;# 或者length2=$&#123;#array[*]&#125;#输出数组长度echo $length #输出：5echo $length2 #输出：5# 输出数组第三个元素echo $&#123;array[2]&#125; #输出：3unset array[1]# 删除下表为1的元素也就是删除第二个元素for i in $&#123;array[@]&#125;;do echo $i ;done # 遍历数组，输出： 1 3 4 5 unset arr_number; # 删除数组中的所有元素for i in $&#123;array[@]&#125;;do echo $i ;done # 遍历数组，数组元素为空，没有任何输出内容 Shell 基本运算符 说明：图片来自《菜鸟教程》 Shell 编程支持下面几种运算符 算数运算符 关系运算符 布尔运算符 字符串运算符 文件测试运算符 算数运算符 我以加法运算符做一个简单的示例： 12345#!/bin/basha=3;b=3;val=`expr $a + $b`#输出：Total value : 6echo "Total value : $val 关系运算符关系运算符只支持数字，不支持字符串，除非字符串的值是数字。 通过一个简单的示例演示关系运算符的使用，下面shell程序的作用是当score=100的时候输出A否则输出B。 123456789#!/bin/bashscore=90;maxscore=100;if [ $score -eq $maxscore ]then echo "A"else echo "B"fi 输出结果： 1B 逻辑运算符 示例： 1234#!/bin/basha=$(( 1 &amp;&amp; 0))# 输出：0；逻辑与运算只有相与的两边都是1，与的结果才是1；否则与的结果是0echo $a; 布尔运算符 这里就不做演示了，应该挺简单的。 字符串运算符 简单示例： 12345678910#!/bin/basha="abc";b="efg";if [ $a = $b ]then echo "a 等于 b"else echo "a 不等于 b"fi 输出： 1a 不等于 b 文件相关运算符 使用方式很简单，比如我们定义好了一个文件路径file=&quot;/usr/learnshell/test.sh&quot; 如果我们想判断这个文件是否可读，可以这样if [ -r $file ] 如果想判断这个文件是否可写，可以这样-w $file，是不是很简单。 shell流程控制if 条件语句简单的 if else-if else 的条件语句示例 123456789101112#!/bin/basha=3;b=9;if [ $a -eq $b ]then echo "a 等于 b"elif [ $a -gt $b ]then echo "a 大于 b"else echo "a 小于 b"fi 输出结果： 1a 小于 b 相信大家通过上面的示例就已经掌握了 shell 编程中的 if 条件语句。不过，还要提到的一点是，不同于我们常见的 Java 以及 PHP 中的 if 条件语句，shell if 条件语句中不能包含空语句也就是什么都不做的语句。 for 循环语句通过下面三个简单的示例认识 for 循环语句最基本的使用，实际上 for 循环语句的功能比下面你看到的示例展现的要大得多。 输出当前列表中的数据： 1234for loop in 1 2 3 4 5do echo "The value is: $loop"done 产生 10 个随机数： 12345#!/bin/bashfor i in &#123;0..9&#125;;do echo $RANDOM;done 输出1到5: 通常情况下 shell 变量调用需要加 $,但是 for 的 (()) 中不需要,下面来看一个例子： 1234#!/bin/bashfor((i=1;i&lt;=5;i++));do echo $i;done; while 语句基本的 while 循环语句： 1234567#!/bin/bashint=1while(( $int&lt;=5 ))do echo $int let "int++"done while循环可用于读取键盘信息： 123456echo '按下 &lt;CTRL-D&gt; 退出'echo -n '输入你最喜欢的电影: 'while read FILMdo echo "是的！$FILM 是一个好电影"done 输出内容: 123按下 &lt;CTRL-D&gt; 退出输入你最喜欢的电影: 变形金刚是的！变形金刚 是一个好电影 无线循环： 1234while truedo commanddone shell 函数不带参数没有返回值的函数1234567#!/bin/bashhello()&#123; echo "这是我的第一个 shell 函数!"&#125;echo "-----函数开始执行-----"helloecho "-----函数执行完毕-----" 输出结果： 123-----函数开始执行-----这是我的第一个 shell 函数!-----函数执行完毕----- 有返回值的函数输入两个数字之后相加并返回结果： 1234567891011#!/bin/bashfunWithReturn()&#123; echo "输入第一个数字: " read aNum echo "输入第二个数字: " read anotherNum echo "两个数字分别为 $aNum 和 $anotherNum !" return $(($aNum+$anotherNum))&#125;funWithReturnecho "输入的两个数字之和为 $?" 输出结果： 123456输入第一个数字: 1输入第二个数字: 2两个数字分别为 1 和 2 !输入的两个数字之和为 3 带参数的函数1234567891011#!/bin/bashfunWithParam()&#123; echo "第一个参数为 $1 !" echo "第二个参数为 $2 !" echo "第十个参数为 $10 !" echo "第十个参数为 $&#123;10&#125; !" echo "第十一个参数为 $&#123;11&#125; !" echo "参数总数有 $# 个!" echo "作为一个字符串输出所有参数 $* !"&#125;funWithParam 1 2 3 4 5 6 7 8 9 34 73 输出结果： 1234567第一个参数为 1 !第二个参数为 2 !第十个参数为 10 !第十个参数为 34 !第十一个参数为 73 !参数总数有 11 个!作为一个字符串输出所有参数 1 2 3 4 5 6 7 8 9 34 73 ! 引用自：https://github.com/Snailclimb/JavaGuide#%E7%BD%91%E7%BB%9C]]></content>
      <categories>
        <category>操作系统</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络-传输层]]></title>
    <url>%2F2019%2F03%2F19%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E4%BC%A0%E8%BE%93%E5%B1%82%2F</url>
    <content type="text"><![CDATA[网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。 UDP 和 TCP 的特点 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 区别1)TCP提供面向连接的、可靠的数据流传输，而UDP提供的是非面向连接的、不可靠的数据流传输。2)TCP传输单位称为TCP报文段，UDP传输单位称为用户数据报。 3)每一条 TCP 连接只能是点对点的,UDP支持一对一、一对多、多对一和多对多。 4)TCP注重数据安全性，UDP数据传输快，因为不需要连接等待，少了许多操作，但是其安全性却一般。 UDP 首部格式 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。 TCP 首部格式 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 TCP 的三次握手 假设 A 为客户端，B 为服务器端。 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认(ACK=1)，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 三次握手的原因 【原因1】第三次握手是为了防止已经失效的连接请求突然又到达服务器，让服务器错误打开连接。 客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。 【原因2】TCP之所以可靠，是因为它保证了传送数据包的顺序。顺序是用一个序列号来保证的。响应包内也包括一个序列号，表示接收方准备好这个序列号的包。显然两次握手不能做到使客户端的序列号发给服务端，并得到服务端的确认，同时服务端产生一个序列号发给客户端，并得到客户端的确认。 TCP 的四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。 A 发送连接释放报文，FIN=1。 B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。 当 B 不再需要连接时，发送连接释放报文，FIN=1。 A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。 B 收到 A 的确认后释放连接。 四次挥手的原因 客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 TIME_WAIT 客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由： 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 TCP 滑动窗口窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。 发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。 接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。 TCP 流量控制流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 TCP 拥塞控制如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。 TCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。 发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。 为了便于讨论，做如下假设： 接收方有足够大的接收缓存，因此不会发生流量控制； 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。 1. 慢开始与拥塞避免发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 … 注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd &gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。 如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。 2. 快重传与快恢复在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。 在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。 在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。 慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。 TCP 怎样保证可靠性（1）序列号、确认应答、超时重传 数据到达接收方，接收方需要发出一个确认应答，表示已经收到该数据段，并且确认序号会说明了它下一次需要接收的数据序列号。如果发送发迟迟未收到确认应答，那么可能是发送的数据丢失，也可能是确认应答丢失，这时发送方在等待一定时间后会进行重传。这个时间一般是2*RTT(报文段往返时间）+一个偏差值。 （2）窗口控制与高速重发控制/快速重传（重复确认应答） TCP会利用窗口控制来提高传输速度，意思是在一个窗口大小内，不用一定要等到应答才能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。 使用窗口控制，如果数据段1001-2000丢失，后面数据每次传输，确认应答都会不停地发送序号为1001的应答，表示我要接收1001开始的数据，发送端如果收到3次相同应答，就会立刻进行重发；但还有种情况有可能是数据都收到了，但是有的应答丢失了，这种情况不会进行重发，因为发送端知道，如果是数据段丢失，接收端不会放过它的，会疯狂向它提醒…… （3）拥塞控制 见上一个标题内容。]]></content>
      <categories>
        <category>计算机网络</category>
        <category>计算机网络理论</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络-物理层]]></title>
    <url>%2F2019%2F03%2F18%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E7%89%A9%E7%90%86%E5%B1%82%2F</url>
    <content type="text"><![CDATA[物理层的基本功能物理层解决如何在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体。 物理层的主要任务描述为：确定传输媒体的接口的一些特性，即： 机械特性：例接口形状，大小，引脚数目 电气特性：例规定电压范围（-5V到+5V） 功能特性：例规定-5V表示0，+5V表示1 过程特性：也称规程特性，规定建立连接时各个相关部件的工作步骤 ==中继器、集线器、网桥、交换机、路由器概念与区别==中继器、集线器、网桥、交换机、路由器概念与区别 1.中继器 中继器，就是简单的信号放大器，使信号能传的更远。 2.集线器 集线器，差不多就是个多端口的中继器，把每个输入端口的信号放大再发到别的端口去，集线器可以实现多台计算机之间的互联，因为它有很多的端口，每个口都能连计算机。 、、、、、、、、、、、、、以上为物理层、、、、、、、、、、、、、、、、、 3.网桥 网桥工作在数据链路层，将两个LAN连起来，根据MAC地址来转发帧，可以看作一个“低层的路由器”。 4.交换机 可以理解为高级的网桥，他有网桥的功能，但性能比网桥强。交换机和网桥的细微差别就在于：交换机常常用来连接独立的计算机**，而网桥连接的目标是LAN，所以交换机的端口较网桥多。** 、、、、、、、、、、、、以上为数据链路层、、、、、、、、、 5.路由器 (网络层) 路由选择与分组转发 6.网关 (网络层) 网关(Gateway)又称网间连接器、协议转换器。网关在网络层以上实现网络互连，是最复杂的网络互连设备，仅用于两个高层协议不同的网络互连。网关既可以用于广域网互连，也可以用于局域网互连。 网关是一种充当转换重任的计算机系统或设备。使用在不同的通信协议、数据格式或语言，甚至体系结构完全不同的两种系统之间，网关是一个翻译器。与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。 网关，从技术角度来解释，就是连接两个不同网络的接口，比如局域网的共享上网服务器就是局域网和广域网的接口。 最后问两个问题： 1.交换机和路由器的区别？ 交换机可以将多台电脑连接起来，与交换机互连的电脑本身则具备了互相通信的功能，组建成了一个内部局域网，但需要访问互联网还需要有网络支持，因此交换机一端需要连接到路由器，路由器即可实现交换功能，还可以拨号，实现宽带连接，并将宽带资源分配个交换机使用，这样就实现了多台电脑共享上网。 ​ 举个例子说明路由器和交换机的配合：我要去找小明借电脑，小明说他不在家，叫我自己去拿吧，同时还告诉我他家的地址是XX路XX小区XX号（好比ip地址），我根据小明告诉我的地址找到了小明的家（路由器的功能，寻找路径）。我进门发现他家居然有10台电脑，哪台是借给我的那台呢？噢，原来小明还告诉我他要借给我的电脑的编号（MAC地址），那样我就可以根据编号找到相应的电脑了。 ​ 在上述的例子中，如果我没有路由器，我就不知道怎么去小明家，更不用说拿到电脑；如果我没有拿到所需的电脑编号，我也拿不到电脑，因为有十台电脑，我不能乱拿；有个特殊情况，如果小明家只有一台电脑呢？那我就不需要编号就可以确定拿哪台电脑，也就是不需要交换机。 2.为什么有时候还要在路由器的后面先接1台交换机再接计算机？ ​ 路由器是可以直接接电脑等终端设备，为什么标准都是路由器接交换机然后再接电脑等终端，是因为路由器本来就是一个路由设备，用来选路的，不适合大量的数据交换，交换机是用来大量数据交换的，终端在内网的性质就是需要使用交换机，所以标准就是路由器地下接交换机的形式。一般是情况就是在路由器下面接交换机，路由器主要起数据转发，也就是寻址、路由的功能，交换机起到用户接入的目的。但是家用的路由器的话直接就接计算机就可以了，而不必考虑再接交换机。 数据通讯的基础知识 半双工和全双工通讯：两者都可发可收，但是半双工不能同时收发，全双工可以。 基带信号和带通信号：基带信号（即基本频带信号）——来自信源的信号。 像计算机输出的代表各种文字或图像文件的数据信号都属于基带信号。基带信号就是发出的直接表达了要传输的信息的信号，比如我们说话的声波就是基带信号 带通信号——把基带信号经过载波调制后，把信号的频率范围搬移到较高的频段以便在信道中传输（即仅在一段频率范围内能够通过信道）。 因此在传输距离较近时，计算机网络都采用基带传输方式由于在近距离范围内基带信号的衰减不大，从而信号内容不会发生变化。因此在传输距离较近时，计算机网络都采用基带传输方式。如从计算机到监视器、打印机等外设的信号就是基带传输的。 对基带数字信号的几种调制方法： 编码方式：** 采用曼切斯特编码，一个时钟周期只可表示一个bit，并且必须通过两次采样才能得到一个bit但它能携带时钟信号，且可表示没有数据传输(没有数据传输就没有电平变化) 差分曼彻斯特编码与曼彻斯特编码相同，但抗干扰性能强于曼彻斯特编码 将1000100111进行曼彻斯特和差分曼彻斯特编码 奈氏准则(没干扰) 1924年，奈奎斯特（Nyquist）就推导出了著名的奈氏准则。他给出了在假定的理想条件下，为了避免码间串扰，码元的传输速率的上限值。 在任何信道中，码元传输的速率是有上限的，否则就会出现码间串扰的问题，使接收端对码元的判决（即识别）成为不可能。如果信道的频带越宽，也就是能够通过的信号高频分量越多，那么就可以用更高的速率传送码元而不出现码间串扰。 香农公式 香农（Shannon）用信息论的理论推导出了带宽受限且有高斯白噪声干扰的信道的极限、无差错的信息传输速率。信道的极限信息传输速率C可表达为 香农公式表明 信道的带宽或信道中的信噪比越大，则信息的极限传输速率就越高。 只要信息传输速率低于信道的极限信息传输速率，就一定可以找到某种办法来实现无差错的传输。 若信道带宽W或信噪比S/N没有上限（当然实际信道不可能是这样的），则信道的极限信息传输速率C也就没有上限。 实际信道上能够达到的信息传输速率要比香农的极限传输速率低不少。]]></content>
      <categories>
        <category>计算机网络</category>
        <category>计算机网络理论</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络-网络层]]></title>
    <url>%2F2019%2F03%2F18%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E7%BD%91%E7%BB%9C%E5%B1%82%2F</url>
    <content type="text"><![CDATA[概述因为网络层是整个互联网的核心，因此应当让网络层尽可能简单。网络层向上只提供简单灵活的、无连接的、尽最大努力交互的数据报服务。 使用 IP 协议，可以把异构的物理网络连接起来，使得在网络层看起来好像是一个统一的网络。 与 IP 协议配套使用的还有三个协议： 地址解析协议 ARP（Address Resolution Protocol） 网际控制报文协议 ICMP（Internet Control Message Protocol） 网际组管理协议 IGMP（Internet Group Management Protocol） IP 数据报格式 版本 : 有 4（IPv4）和 6（IPv6）两个值； 首部长度 : 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为固定部分长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。 区分服务 : 用来获得更好的服务，一般情况下不使用。 总长度 : 包括首部长度和数据部分长度。 生存时间 ：TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。 协议 ：指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。 首部检验和 ：因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。 标识 : 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。 片偏移 : 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。 ==IP 地址编址方式==IP 地址的编址方式经历了三个历史阶段： 1. 分类由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 主机号 &gt;} 2. 子网划分通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。 IP 地址 ::= {&lt; 网络号 &gt;, &lt; 子网号 &gt;, &lt; 主机号 &gt;} 要使用子网，必须配置子网掩码。 注意，外部网络看不到子网的存在。 3. 无分类无分类编址 CIDR 消除了传统 A 类、B 类和 C 类地址以及划分子网的概念，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。 IP 地址 ::= {&lt; 网络前缀号 &gt;, &lt; 主机号 &gt;} CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。 CIDR 的地址掩码可以继续称为子网掩码，子网掩码首 1 长度为网络前缀的长度。 一个 CIDR 地址块中有很多地址，一个 CIDR 表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为 构成超网 。 在路由表中的项目由“网络前缀”和“下一跳地址”组成，在查找时可能会得到不止一个匹配结果，应当采用最长前缀匹配来确定应该匹配哪一个。 ==地址解析协议 ARP==网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。 ARP 实现由 IP 地址得到 MAC 地址。 每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。 如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。 ARP欺骗,用于监听(回复解析的MAC，对真实回复的MAC进行覆盖)，用于让目标机无法接受(传个不存在的MAC)(工具：网络执法官，防止：ARP防火墙) ==网际控制报文协议 ICMP==用于实现链路连通性测试和链路追踪，可以实现链路差错报告，属于UDP协议。 ping、tracert 等命令的内部就是用的 icmp 协议。 ==网络组管理协议 IGMP==信道分类 点到点： 广播：目标地址全FF 发一个包，所有的都可以接受 组播=多播： 组播类似于频道，例如开视频会议，总部在北京，领导讲话，上海所有员工需要观看，其他地方员工不用看到。 而IGMP协议是指英文全称（Internet Group Management Protocol），网络组管理协议。主要用于建立和管理多播组，对IP分组广播进行控制。 协议号： ICMP协议号1 IGMP协议2 TCP 6 UDP 17 IPv6 41 0SPF 89 静态路由与动态路由现将静态路由和动态路由进行如下比较： 定义： 静态路由：静态路由是在路由器中设置固定的路由表；除非网络管理员进行干预，否则静态路由表不会发生变化。 动态路由：由网络中的路由器之间相互通信，传递路由信息，利用收到的路由信息更新路由表的路由方式。 优点： 静态路由：简单、高效、可靠、网络安全、转发效率高。 动态路由：灵活，能够适时适应网络结构的变化，无需管理员手工维护，减轻了管理员的工作负担。 缺点： 静态路由：不能灵活的适应网络的动态变化。 动态路由：占用网络带宽（用于传输路由更新信息）。 使用场景： 静态路由：网络规模不大，拓扑结构固定的网络中。 动态路由：网络规模大，网络拓扑机构复杂的网络。]]></content>
      <categories>
        <category>计算机网络</category>
        <category>计算机网络理论</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络-应用层]]></title>
    <url>%2F2019%2F03%2F18%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E5%BA%94%E7%94%A8%E5%B1%82%2F</url>
    <content type="text"><![CDATA[域名系统DNSDNS服务作用：负责将域名解析成IP DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。 域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。 DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输： 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 文件传送协议FTPFTP 使用 TCP 进行连接，它需要两个连接来传送一个文件： 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。 动态主机配置协议DHCPDHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。 DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。 DHCP 工作过程如下： 客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。 DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。 DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。 远程登录协议TELNETTELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。 TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。 电子邮件协议一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。 邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。 1. SMTP(发送)SMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。 2. POP3(接收)POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。 3. IMAP(接收)IMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。 常用端口 应用 应用层协议 端口号 传输层协议 备注 域名解析 DNS 53 UDP/TCP 长度超过 512 字节时使用 TCP 动态主机配置协议 DHCP 67/68 UDP 简单网络管理协议 SNMP 161/162 UDP 文件传送协议 FTP 20/21 TCP 控制连接 21，数据连接 20 远程终端协议 TELNET 23 TCP 超文本传送协议 HTTP 80 TCP 简单邮件传送协议 SMTP 25 TCP 邮件读取协议 POP3 110 TCP 网际报文存取协议 IMAP 143 TCP 在浏览器地址栏键入URL，按下回车之后会经历以下流程：1、浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址; 2、解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立TCP连接; 3、浏览器发出读取文件(URL 中域名后面部分对应的文件)的HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器; 4、服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器; 5、释放 TCP连接; 6、浏览器将该 html 文本并显示内容; Web 页面请求详细过程1. DHCP 配置主机信息 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:FF:FF:FF:FF:FF，将广播到与交换机连接的所有设备。 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。 2. ARP 解析 MAC 地址 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。 主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。 该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。 该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。 DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。 主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。 网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。 3. DNS 解析域名 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。 网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。 因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。 到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。 4. HTTP 请求页面 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。 HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。 HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。]]></content>
      <categories>
        <category>计算机网络</category>
        <category>计算机网络理论</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL语句]]></title>
    <url>%2F2019%2F03%2F17%2FSQL%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[● 常用SQL语句（DDL,DML,DCL,TCL）数据查询语言(DQL-Data Query Language) 代表关键字:select 数据操纵语言(DML-Data Manipulation Language) 增删改，针对表的数据 代表关键字:insert,delete,update 数据定义语言(DDL-Data Definition Language) 增删改，针对表的结构 代表关键字:create ,drop,alter, 事务控制语言(TCL-Transactional Control Language) 提交，回滚 代表关键字:commit ,rollback; 数据控制语言(DCL-Data Control Language) 代表关键字:grant,revoke. ●数据定义语句(create、drop、alter)1.定义基本表 SQL 语言使用CREATETABLE语句定义基本表，其基本格式如下： 建立一个“学生信息”表Student： 2.修改基本表 随着应用环境和应用需求的变化，有时需要修改已建立好的基本表，SQL 语言用ALTER TABLE语句修改基本表，其一般格式为： 其中，&lt;表名&gt;是要修改的表，ADD子句用于增加新列和新的完整性约束条件，DROP子句用于删除指定的完整性约束条件，MODIFY COLUMN子句用于修改原有的列定义，包括修改列名和数据类型。 例1：向Student表增加“入学时间”列，其数据类型为日期型。 1ALTER TABLE Student ADD S entrance DATE； 上述代码不论基本表中原来是否已有数据，新增加的列一律为空值。 例2：要求将年龄的数据类型由字符型（假设原来的数据类型是字符型）改为整数。 1ALTER TABLE Student MODIFY COLUMN Sage INT； 例3：增加Student表Sname必须取唯一值的约束条件： 1ALTER TABLE Student ADD UNIQUE（Sname）； 3.删除基本表 当某个基本表不再需要时，可以使用DROPTABLE语句删除它。其一般格式为： 1DROP TABLE&lt;表名&gt; [RESTRICT ICASCADE]； 若选择RESTRICT，则该表的删除是有限制条件的：欲删除的基本表不能被其他表的约束所引用（如check，foreign key等约束），不能有视图，不能有触发器，不能有存储过程或函数等。如果存在这些依赖该表的对象，则此表不能被删除。 若选择CASCADE，则该表的删除没有限制条件。在删除该表的同时，相关的依赖对象，例如视图，都将被一起删除。删除Student表： 1DROP TABLE Student CASCADE； ●数据查询(select) 整个SELECT语句的含义是：根据WHERE子句的条件表达式，从FROM子句指定的基本表或视图中找出满足条件的元组，再按SELECT子句中的目标列表达式，选出元组中的属性值形成结果表。 如果有GROUP BY子句，则将结果按&lt;列名1&gt;的值进行分组，该属性列值相等的元组为一个组。 通常会在每组中作用聚集函数。如果GROUPBY子句带HAVING子句，则只有满足指定条件的组才予以输出。如果有ORDER BY子句，则结果表还要按&lt;列名2&gt;的值的升序或降序排序。 1.选择表中的若干列 假设在表Student（1.2.1节中已定义）中，查询名为BilGates的学生信息，你可以使用下面的查询： 1SELECT*from Student WHERE Sname='Bill Gates'； 假设在表Student中，查询名字中有Bill的学生信息，你可以使用下面的查询： 1SELECT*from Student WHERE Sname like'$Bill%'； 上述%是通配符，代表任意长度（可为0）的字符串。例如a%b表示以a开头，以b结尾的任意长度的字符串。除此之外，（下画线）代表任意单词字符。 假设在表Student中查询年龄在20~23岁（包括20岁与23岁）之间的学生的信息： 1SELECT*FROM Student WHERE Sage BETWEEN 20 AND 23； 与BETWEEN…AND…相对的谓词是NOT BETWEEN·…AND…。 假设在表Student中查询计算机系（CS）、信息系（MA）和数学系（IS）学生的姓名和性别： 1SELECT Sname，Ssex FROM Student WHERE Sdept IN（'CS'，'IS'，'MA'）； 与IN相对的谓词是NOTIN，用于查找属性值不属于指定集合的元组。 假设在表Student中查询没有年龄信息的学生： 1SELECT * FROM Student WHERE Sage IS NULL； 注意这里的“IS”不能被等号代替。 2.ORDER BY子句 用户可以用order by子句对查询的结果按照一个或多个属性列的升序（ASC）或降序（DESC）排列，默认值为升序。 例如在表Student中，按学生的年龄值升序检索出全部学生的信息： 1SELECT * FROM Student ORDER BY Sage； 在表Student中，先按专业升序排序，然后同一专业的学生再按年龄降序排序，并输出全部学生信息： 1SELECT * FROM Student ORDER BY Sdept，Sage desc； 3.LIMIT子句 LIMIT主要是用于查询之后要显示返回的前几条或者中间某几行数据。 1SELECT * FROM table LIMIT[offset，]rows I rows OFFSET offset LIMIT子句可以被用于强制SELECT 语句返回指定的记录数。LIMIT接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。初始记录行的偏移量是0（而不是1）。如： 1SELECT * FROM Student LIMIT 5，10；//检索记录行6-15 如果只给定一个参数，它表示返回最前面的记录行数目： 1SELECT*FROM Student LIMIT 5；//检索前5个记录行 换句话说，LIMITn等价于LIMIT0，n。 例1：如下SQL语句是需要列出一个论坛版面第一页（每页显示20个）的帖子（post）标题（title），并按照发布时间（create_time）降序排列：（2012·腾讯） 1SELECT title FROM post ? create_time DESC ? 0，20； 解答：order by，limit。 4.聚集函数 SQL 语句中常用的聚集函数有以下几种：count，sum，avg，max，min。用法如下： 总数：select count（*）as totalcount from table1； 求和：select sum（field1）as sumvalue from table1； 平均：select avg（field1）as avgvalue from table1； 最大：select max（field1）as maxvalue from table1； 最小：select min（field1）as minvalue from table1； 例1：在SQL中，用于聚集查询的函数有哪些？（2012·搜狗） 解答：count，sum，avg，max，min。 5.GROUP BY子句 GROUP BY子句根据一个或多个属性的值来对元组进行分组，值相等的为一组。 对查询结果分组的目的是为了细化聚集函数的作用对象，分组后聚集函数将作用于每一个组，即每一组都有一个函数值，如下列语句为查询Student 表中具有相同年龄的每个组的人数： 1select Sage，count（*）from Student group by Sage； 如果分组后还要求按一定的条件对这些组进行筛选，最终只输出满足指定条件的组，则使用HAVING短语指定筛选条件。 通常，HAVING子句只用在GROUPBY子句的SQL语句中，用来选取符合指定条件的分组。例如： 1select Sage，count（*）from Student group by Sage having count（*）&gt;1； 6.连接查询 前面的查询都是针对一个表进行的。若一个查询同时涉及两个以上的表，则称之为连接查询。若有表Student（学生信息表）、SC（选课表），要求查询每个学生及其选修课程的情况： 1SELECT Student.*，SC.* FROM Student，SC WHERE Student.Sno=SC.Sno； 在以上的连接操作中，只有满足条件的元组才能作为结果输出。若表Student中某些学生没有选课，则在SC表中没有相应的元组，造成最终结果中舍弃掉了这些学生的信息。 上述连接称为自然连接、内连接。 有时想以Student表为主体列出每个学生的基本情况及其选课情况。若某个学生没有选课，依然将其保存到结果中（在SC表的属性上填空值），这时就需要使用外连接。 1SELECT Student.*，SC.* FROM Student LEFT JOIN SC ON（Student.Sno=SC.Sno）; 以上是左外连接，左外连接列出左边表（本例为Student表）中的所有元组，右外连接列出右表关系中所有的元组。 ●数据操纵(insert,delete,update)数据操纵操作有3种：向表中添加若干行数据、修改表中的数据和删除表中的若干行数据。 1.插入元组 插入元组的INSERT语句的格式为： 12INSERT INTO tablel（fieldl，field2..） VALUES（value1，value2..）; 其功能是将新元组插入到指定表中。其中新元组的fieldl的值为valuel，field2的值为value2… 如果INTO语句中没有指定任何属性列名，则新插入的元组必须在每个属性列上均有值。 将一个新学生元组（学号：201009013；姓名：王明；性别：男；所在系：CS；年龄：23）插入到Student表中的语句为： 12INSERT INTO Student（Sno，Sname，Ssex，Sdept，Sage） VALUES（'201009013'，'王明’，‘M'，'CS'，23）； 2.修改数据 修改数据又称为更新操作，其语句的一般格式为： 123UPDATE table1 SET fieldl=valuel，field2=value2 WHERE范围； 其功能是修改指定表中满足WHERE子句条件的元组。其中SET子句给出的value值用于取代相应的属性列值。如果省略WHERE子句，则表示要修改表中的所有元组。 将学生201009013的年龄改为22岁： 123UPDATE Student SET Sage=22 WHERE Sno='201009013'； 3.删除数据 删除语句的一般格式为： 123DELETE FROM table1 WHERE范围； DELETE语句的功能是从指定表中删除满足WHERE子句条件的所有元组。如果省略 WHERE子句，表示删除表中全部元组，但表仍存在。删除学号为201009013的学生记录： 123DELETE FROM Student WHERE Sno='201009013'；]]></content>
      <categories>
        <category>数据库</category>
        <category>SQL语句</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>SQL语句</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode数据库题解]]></title>
    <url>%2F2019%2F03%2F17%2FLeetcode-Database%20%E9%A2%98%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[595. Big Countrieshttps://leetcode.com/problems/big-countries/description/ Description123456789+-----------------+------------+------------+--------------+---------------+| name | continent | area | population | gdp |+-----------------+------------+------------+--------------+---------------+| Afghanistan | Asia | 652230 | 25500100 | 20343000 || Albania | Europe | 28748 | 2831741 | 12960000 || Algeria | Africa | 2381741 | 37100000 | 188681000 || Andorra | Europe | 468 | 78115 | 3712000 || Angola | Africa | 1246700 | 20609294 | 100990000 |+-----------------+------------+------------+--------------+---------------+ 查找面积超过 3,000,000 或者人口数超过 25,000,000 的国家。 123456+--------------+-------------+--------------+| name | population | area |+--------------+-------------+--------------+| Afghanistan | 25500100 | 652230 || Algeria | 37100000 | 2381741 |+--------------+-------------+--------------+ SQL SchemaSQL Schema 用于在本地环境下创建表结构并导入数据，从而方便在本地环境解答。 1234567891011DROP TABLEIF EXISTS World;CREATE TABLE World ( NAME VARCHAR ( 255 ), continent VARCHAR ( 255 ), area INT, population INT, gdp INT );INSERT INTO World ( NAME, continent, area, population, gdp )VALUES ( 'Afghanistan', 'Asia', '652230', '25500100', '203430000' ), ( 'Albania', 'Europe', '28748', '2831741', '129600000' ), ( 'Algeria', 'Africa', '2381741', '37100000', '1886810000' ), ( 'Andorra', 'Europe', '468', '78115', '37120000' ), ( 'Angola', 'Africa', '1246700', '20609294', '1009900000' ); Solution12345678SELECT name, population, areaFROM WorldWHERE area &gt; 3000000 OR population &gt; 25000000; 627. Swap Salaryhttps://leetcode.com/problems/swap-salary/description/ Description123456| id | name | sex | salary ||----|------|-----|--------|| 1 | A | m | 2500 || 2 | B | f | 1500 || 3 | C | m | 5500 || 4 | D | f | 500 | 只用一个 SQL 查询，将 sex 字段反转。 123456| id | name | sex | salary ||----|------|-----|--------|| 1 | A | f | 2500 || 2 | B | m | 1500 || 3 | C | f | 5500 || 4 | D | m | 500 | SQL Schema12345678910DROP TABLEIF EXISTS salary;CREATE TABLE salary ( id INT, NAME VARCHAR ( 100 ), sex CHAR ( 1 ), salary INT );INSERT INTO salary ( id, NAME, sex, salary )VALUES ( '1', 'A', 'm', '2500' ), ( '2', 'B', 'f', '1500' ), ( '3', 'C', 'm', '5500' ), ( '4', 'D', 'f', '500' ); Solution使用异或操作，两个相等的数异或的结果为 0，而 0 与任何一个数异或的结果为这个数。 12&apos;f&apos; ^ &apos;m&apos; ^ &apos;f&apos; = &apos;m&apos;&apos;m&apos; ^ &apos;m&apos; ^ &apos;f&apos; = &apos;f&apos; 12UPDATE salarySET sex = CHAR ( ASCII(sex) ^ ASCII( 'm' ) ^ ASCII( 'f' ) ); 620. Not Boring Movieshttps://leetcode.com/problems/not-boring-movies/description/ Description123456789+---------+-----------+--------------+-----------+| id | movie | description | rating |+---------+-----------+--------------+-----------+| 1 | War | great 3D | 8.9 || 2 | Science | fiction | 8.5 || 3 | irish | boring | 6.2 || 4 | Ice song | Fantacy | 8.6 || 5 | House card| Interesting| 9.1 |+---------+-----------+--------------+-----------+ 查找 id 为奇数，并且 description 不是 boring 的电影，按 rating 降序。 123456+---------+-----------+--------------+-----------+| id | movie | description | rating |+---------+-----------+--------------+-----------+| 5 | House card| Interesting| 9.1 || 1 | War | great 3D | 8.9 |+---------+-----------+--------------+-----------+ SQL Schema1234567891011DROP TABLEIF EXISTS cinema;CREATE TABLE cinema ( id INT, movie VARCHAR ( 255 ), description VARCHAR ( 255 ), rating FLOAT ( 2, 1 ) );INSERT INTO cinema ( id, movie, description, rating )VALUES ( 1, 'War', 'great 3D', 8.9 ), ( 2, 'Science', 'fiction', 8.5 ), ( 3, 'irish', 'boring', 6.2 ), ( 4, 'Ice song', 'Fantacy', 8.6 ), ( 5, 'House card', 'Interesting', 9.1 ); Solution123456789SELECT *FROM cinemaWHERE id % 2 = 1 AND description != 'boring'ORDER BY rating DESC; 596. Classes More Than 5 Studentshttps://leetcode.com/problems/classes-more-than-5-students/description/ Description12345678910111213+---------+------------+| student | class |+---------+------------+| A | Math || B | English || C | Math || D | Biology || E | Math || F | Computer || G | Math || H | Math || I | Math |+---------+------------+ 查找有五名及以上 student 的 class。 12345+---------+| class |+---------+| Math |+---------+ SQL Schema123456789101112131415DROP TABLEIF EXISTS courses;CREATE TABLE courses ( student VARCHAR ( 255 ), class VARCHAR ( 255 ) );INSERT INTO courses ( student, class )VALUES ( 'A', 'Math' ), ( 'B', 'English' ), ( 'C', 'Math' ), ( 'D', 'Biology' ), ( 'E', 'Math' ), ( 'F', 'Computer' ), ( 'G', 'Math' ), ( 'H', 'Math' ), ( 'I', 'Math' ); Solution对 class 列进行分组之后，再使用 count 汇总函数统计数量，统计之后使用 having 进行过滤。 12345678SELECT classFROM coursesGROUP BY classHAVING count( DISTINCT student ) &gt;= 5; 182. Duplicate Emailshttps://leetcode.com/problems/duplicate-emails/description/ Description邮件地址表： 1234567+----+---------+| Id | Email |+----+---------+| 1 | a@b.com || 2 | c@d.com || 3 | a@b.com |+----+---------+ 查找重复的邮件地址： 12345+---------+| Email |+---------+| a@b.com |+---------+ SQL Schema123456789DROP TABLEIF EXISTS Person;CREATE TABLE Person ( Id INT, Email VARCHAR ( 255 ) );INSERT INTO Person ( Id, Email )VALUES ( 1, 'a@b.com' ), ( 2, 'c@d.com' ), ( 3, 'a@b.com' ); Solution对 Email 进行分组，如果相同 Email 的数量大于等于 2，则表示该 Email 重复。 12345678SELECT EmailFROM PersonGROUP BY EmailHAVING COUNT( * ) &gt;= 2; 196. Delete Duplicate Emailshttps://leetcode.com/problems/delete-duplicate-emails/description/ Description邮件地址表： 1234567+----+---------+| Id | Email |+----+---------+| 1 | john@example.com || 2 | bob@example.com || 3 | john@example.com |+----+---------+ 删除重复的邮件地址： 123456+----+------------------+| Id | Email |+----+------------------+| 1 | john@example.com || 2 | bob@example.com |+----+------------------+ SQL Schema与 182 相同。 Solution只保留相同 Email 中 Id 最小的那一个，然后删除其它的。 连接： 1234567DELETE p1FROM Person p1, Person p2WHERE p1.Email = p2.Email AND p1.Id &gt; p2.Id 子查询： 12345DELETEFROM PersonWHERE id NOT IN ( SELECT id FROM ( SELECT min( id ) AS id FROM Person GROUP BY email ) AS m ); 应该注意的是上述解法额外嵌套了一个 SELECT 语句，如果不这么做，会出现错误：You can’t specify target table ‘Person’ for update in FROM clause。以下演示了这种错误解法。 12345DELETEFROM PersonWHERE id NOT IN ( SELECT min( id ) AS id FROM Person GROUP BY email ); 参考：pMySQL Error 1093 - Can’t specify target table for update in FROM clause 175. Combine Two Tableshttps://leetcode.com/problems/combine-two-tables/description/ DescriptionPerson 表： 12345678+-------------+---------+| Column Name | Type |+-------------+---------+| PersonId | int || FirstName | varchar || LastName | varchar |+-------------+---------+PersonId is the primary key column for this table. Address 表： 123456789+-------------+---------+| Column Name | Type |+-------------+---------+| AddressId | int || PersonId | int || City | varchar || State | varchar |+-------------+---------+AddressId is the primary key column for this table. 查找 FirstName, LastName, City, State 数据，而不管一个用户有没有填地址信息。 SQL Schema1234567891011121314DROP TABLEIF EXISTS Person;CREATE TABLE Person ( PersonId INT, FirstName VARCHAR ( 255 ), LastName VARCHAR ( 255 ) );DROP TABLEIF EXISTS Address;CREATE TABLE Address ( AddressId INT, PersonId INT, City VARCHAR ( 255 ), State VARCHAR ( 255 ) );INSERT INTO Person ( PersonId, LastName, FirstName )VALUES ( 1, 'Wang', 'Allen' );INSERT INTO Address ( AddressId, PersonId, City, State )VALUES ( 1, 2, 'New York City', 'New York' ); Solution涉及到 Person 和 Address 两个表，在对这两个表执行连接操作时，因为要保留 Person 表中的信息，即使在 Address 表中没有关联的信息也要保留。此时可以用左外连接，将 Person 表放在 LEFT JOIN 的左边。 123456789SELECT FirstName, LastName, City, StateFROM Person P LEFT JOIN Address A ON P.PersonId = A.PersonId; 181. Employees Earning More Than Their Managershttps://leetcode.com/problems/employees-earning-more-than-their-managers/description/ DescriptionEmployee 表： 12345678+----+-------+--------+-----------+| Id | Name | Salary | ManagerId |+----+-------+--------+-----------+| 1 | Joe | 70000 | 3 || 2 | Henry | 80000 | 4 || 3 | Sam | 60000 | NULL || 4 | Max | 90000 | NULL |+----+-------+--------+-----------+ 查找薪资大于其经理薪资的员工信息。 SQL Schema12345678910DROP TABLEIF EXISTS Employee;CREATE TABLE Employee ( Id INT, NAME VARCHAR ( 255 ), Salary INT, ManagerId INT );INSERT INTO Employee ( Id, NAME, Salary, ManagerId )VALUES ( 1, 'Joe', 70000, 3 ), ( 2, 'Henry', 80000, 4 ), ( 3, 'Sam', 60000, NULL ), ( 4, 'Max', 90000, NULL ); Solution1234567SELECT E1.NAME AS EmployeeFROM Employee E1 INNER JOIN Employee E2 ON E1.ManagerId = E2.Id AND E1.Salary &gt; E2.Salary; 183. Customers Who Never Orderhttps://leetcode.com/problems/customers-who-never-order/description/ DescriptionCustomers 表： 12345678+----+-------+| Id | Name |+----+-------+| 1 | Joe || 2 | Henry || 3 | Sam || 4 | Max |+----+-------+ Orders 表： 123456+----+------------+| Id | CustomerId |+----+------------+| 1 | 3 || 2 | 1 |+----+------------+ 查找没有订单的顾客信息： 123456+-----------+| Customers |+-----------+| Henry || Max |+-----------+ SQL Schema123456789101112131415161718DROP TABLEIF EXISTS Customers;CREATE TABLE Customers ( Id INT, NAME VARCHAR ( 255 ) );DROP TABLEIF EXISTS Orders;CREATE TABLE Orders ( Id INT, CustomerId INT );INSERT INTO Customers ( Id, NAME )VALUES ( 1, 'Joe' ), ( 2, 'Henry' ), ( 3, 'Sam' ), ( 4, 'Max' );INSERT INTO Orders ( Id, CustomerId )VALUES ( 1, 3 ), ( 2, 1 ); Solution左外链接 12345678SELECT C.Name AS CustomersFROM Customers C LEFT JOIN Orders O ON C.Id = O.CustomerIdWHERE O.CustomerId IS NULL; 子查询 123456SELECT Name AS CustomersFROM CustomersWHERE Id NOT IN ( SELECT CustomerId FROM Orders ); 184. Department Highest Salaryhttps://leetcode.com/problems/department-highest-salary/description/ DescriptionEmployee 表： 12345678+----+-------+--------+--------------+| Id | Name | Salary | DepartmentId |+----+-------+--------+--------------+| 1 | Joe | 70000 | 1 || 2 | Henry | 80000 | 2 || 3 | Sam | 60000 | 2 || 4 | Max | 90000 | 1 |+----+-------+--------+--------------+ Department 表： 123456+----+----------+| Id | Name |+----+----------+| 1 | IT || 2 | Sales |+----+----------+ 查找一个 Department 中收入最高者的信息： 123456+------------+----------+--------+| Department | Employee | Salary |+------------+----------+--------+| IT | Max | 90000 || Sales | Henry | 80000 |+------------+----------+--------+ SQL Schema1234567891011121314DROP TABLE IF EXISTS Employee;CREATE TABLE Employee ( Id INT, NAME VARCHAR ( 255 ), Salary INT, DepartmentId INT );DROP TABLE IF EXISTS Department;CREATE TABLE Department ( Id INT, NAME VARCHAR ( 255 ) );INSERT INTO Employee ( Id, NAME, Salary, DepartmentId )VALUES ( 1, 'Joe', 70000, 1 ), ( 2, 'Henry', 80000, 2 ), ( 3, 'Sam', 60000, 2 ), ( 4, 'Max', 90000, 1 );INSERT INTO Department ( Id, NAME )VALUES ( 1, 'IT' ), ( 2, 'Sales' ); Solution创建一个临时表，包含了部门员工的最大薪资。可以对部门进行分组，然后使用 MAX() 汇总函数取得最大薪资。 之后使用连接找到一个部门中薪资等于临时表中最大薪资的员工。 123456789101112SELECT D.NAME Department, E.NAME Employee, E.SalaryFROM Employee E, Department D, ( SELECT DepartmentId, MAX( Salary ) Salary FROM Employee GROUP BY DepartmentId ) MWHERE E.DepartmentId = D.Id AND E.DepartmentId = M.DepartmentId AND E.Salary = M.Salary; 176. Second Highest Salaryhttps://leetcode.com/problems/second-highest-salary/description/ Description1234567+----+--------+| Id | Salary |+----+--------+| 1 | 100 || 2 | 200 || 3 | 300 |+----+--------+ 查找工资第二高的员工。 12345+---------------------+| SecondHighestSalary |+---------------------+| 200 |+---------------------+ 没有找到返回 null 而不是不返回数据。 SQL Schema123456789DROP TABLEIF EXISTS Employee;CREATE TABLE Employee ( Id INT, Salary INT );INSERT INTO Employee ( Id, Salary )VALUES ( 1, 100 ), ( 2, 200 ), ( 3, 300 ); Solution为了在没有查找到数据时返回 null，需要在查询结果外面再套一层 SELECT。 12SELECT ( SELECT DISTINCT Salary FROM Employee ORDER BY Salary DESC LIMIT 1, 1 ) SecondHighestSalary; 177. Nth Highest SalaryDescription查找工资第 N 高的员工。 SQL Schema同 176。 Solution123456CREATE FUNCTION getNthHighestSalary ( N INT ) RETURNS INT BEGINSET N = N - 1;RETURN ( SELECT ( SELECT DISTINCT Salary FROM Employee ORDER BY Salary DESC LIMIT N, 1 ) );END 178. Rank Scoreshttps://leetcode.com/problems/rank-scores/description/ Description得分表： 12345678910+----+-------+| Id | Score |+----+-------+| 1 | 3.50 || 2 | 3.65 || 3 | 4.00 || 4 | 3.85 || 5 | 4.00 || 6 | 3.65 |+----+-------+ 将得分排序，并统计排名。 12345678910+-------+------+| Score | Rank |+-------+------+| 4.00 | 1 || 4.00 | 1 || 3.85 | 2 || 3.65 | 3 || 3.65 | 3 || 3.50 | 4 |+-------+------+ SQL Schema123456789101112DROP TABLEIF EXISTS Scores;CREATE TABLE Scores ( Id INT, Score DECIMAL ( 3, 2 ) );INSERT INTO Scores ( Id, Score )VALUES ( 1, 3.5 ), ( 2, 3.65 ), ( 3, 4.0 ), ( 4, 3.85 ), ( 5, 4.0 ), ( 6, 3.65 ); Solution要统计某个 score 的排名，只要统计大于该 score 的 score 数量，然后加 1。 score 大于该 score 的 score 数量 排名 4.1 2 3 4.2 1 2 4.3 0 1 但是在本题中，相同的 score 只算一个排名： score 排名 4.1 3 4.1 3 4.2 2 4.2 2 4.3 1 4.3 1 可以按 score 进行分组，将同一个分组中的 score 只当成一个。 但是如果分组字段只有 score 的话，那么相同的 score 最后的结果只会有一个，例如上面的 6 个记录最后只取出 3 个。 score 排名 4.1 3 4.2 2 4.3 1 所以在分组中需要加入 Id，每个记录显示一个结果。综上，需要使用 score 和 id 两个分组字段。 在下面的实现中，首先将 Scores 表根据 score 字段进行自连接，得到一个新表，然后在新表上对 id 和 score 进行分组。 1234567891011SELECT S1.score 'Score', COUNT( DISTINCT S2.score ) 'Rank'FROM Scores S1 INNER JOIN Scores S2 ON S1.score &lt;= S2.scoreGROUP BY S1.id, S1.scoreORDER BY S1.score DESC; 180. Consecutive Numbershttps://leetcode.com/problems/consecutive-numbers/description/ Description数字表： 1234567891011+----+-----+| Id | Num |+----+-----+| 1 | 1 || 2 | 1 || 3 | 1 || 4 | 2 || 5 | 1 || 6 | 2 || 7 | 2 |+----+-----+ 查找连续出现三次的数字。 12345+-----------------+| ConsecutiveNums |+-----------------+| 1 |+-----------------+ SQL Schema12345678910111213DROP TABLEIF EXISTS LOGS;CREATE TABLE LOGS ( Id INT, Num INT );INSERT INTO LOGS ( Id, Num )VALUES ( 1, 1 ), ( 2, 1 ), ( 3, 1 ), ( 4, 2 ), ( 5, 1 ), ( 6, 2 ), ( 7, 2 ); Solution12345678910SELECT DISTINCT L1.num ConsecutiveNumsFROM Logs L1, Logs L2, Logs L3WHERE L1.id = l2.id - 1 AND L2.id = L3.id - 1 AND L1.num = L2.num AND l2.num = l3.num; 626. Exchange Seatshttps://leetcode.com/problems/exchange-seats/description/ Descriptionseat 表存储着座位对应的学生。 123456789+---------+---------+| id | student |+---------+---------+| 1 | Abbot || 2 | Doris || 3 | Emerson || 4 | Green || 5 | Jeames |+---------+---------+ 要求交换相邻座位的两个学生，如果最后一个座位是奇数，那么不交换这个座位上的学生。 123456789+---------+---------+| id | student |+---------+---------+| 1 | Doris || 2 | Abbot || 3 | Green || 4 | Emerson || 5 | Jeames |+---------+---------+ SQL Schema1234567891011DROP TABLEIF EXISTS seat;CREATE TABLE seat ( id INT, student VARCHAR ( 255 ) );INSERT INTO seat ( id, student )VALUES ( '1', 'Abbot' ), ( '2', 'Doris' ), ( '3', 'Emerson' ), ( '4', 'Green' ), ( '5', 'Jeames' ); Solution使用多个 union。 123456789101112131415161718192021222324252627282930# 处理偶数 id，让 id 减 1# 例如 2,4,6,... 变成 1,3,5,...SELECT s1.id - 1 AS id, s1.studentFROM seat s1WHERE s1.id MOD 2 = 0 UNION# 处理奇数 id，让 id 加 1。但是如果最大的 id 为奇数，则不做处理# 例如 1,3,5,... 变成 2,4,6,...SELECT s2.id + 1 AS id, s2.studentFROM seat s2WHERE s2.id MOD 2 = 1 AND s2.id != ( SELECT max( s3.id ) FROM seat s3 ) UNION# 如果最大的 id 为奇数，单独取出这个数SELECT s4.id AS id, s4.studentFROM seat s4WHERE s4.id MOD 2 = 1 AND s4.id = ( SELECT max( s5.id ) FROM seat s5 )ORDER BY id;]]></content>
      <categories>
        <category>数据库</category>
        <category>Leetcode数据库题解</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Leetcode数据库题解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络-概述]]></title>
    <url>%2F2019%2F03%2F17%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[网络的网络网络把主机连接起来，而互联网是把多种不同的网络连接起来，因此互联网是网络的网络。 ISP互联网服务提供商 ISP 可以从互联网管理机构获得许多 IP 地址，同时拥有通信线路以及路由器等联网设备，个人或机构向 ISP 缴纳一定的费用就可以接入互联网。 目前的互联网是一种多层次 ISP 结构，ISP 根据覆盖面积的大小分为第一层 ISP、区域 ISP 和接入 ISP。互联网交换点 IXP 允许两个 ISP 直接相连而不用经过第三个 ISP。 主机之间的通信方式 客户-服务器（C/S）：客户是服务的请求方，服务器是服务的提供方。 对等（P2P）：不区分客户和服务器。 ==网络参考模型== 注意：TCP/IP 协议实际用的是4层，5层和7层一般用来教学。 OSI分层 （7层）：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。TCP/IP分层（4层）：网络接口层、 网际层、运输层、 应用层。五层协议 （5层）：物理层、数据链路层、网络层、运输层、 应用层。 每一层的协议如下： 物理层：RJ45、CLOCK、IEEE802.3 （中继器，集线器） 数据链路：PPP、FR、HDLC、VLAN、MAC （网桥，交换机） 网络层：IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP、 （路由器） 传输层：TCP、UDP、SPX 会话层：NFS、SQL、NETBIOS、RPC 表示层：JPEG、MPEG、ASII 应用层：FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS 物理层：激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性。该层为上层协议提供了一个传输数据的物理媒体。两个重要的设备名称，中继器（Repeater，也叫放大器）和集线器。 数据链路层 ：数据链路层在不可靠的物理介质上提供可靠的传输。该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。 数据链路层为网络层提供可靠的数据传输；基本数据单位为帧；主要的协议：以太网协议；两个重要设备名称：网桥和交换机。 网络层 ：**网络层负责对子网间的数据包进行路由选择。此外，网络层还可以实现拥塞控制、网际互连等功能。**基本数据单位为IP数据报； 包含的主要协议：IP协议（Internet Protocol，因特网互联协议）;ICMP协议（Internet Control Message Protocol，因特网控制报文协议）;ARP协议（Address Resolution Protocol，地址解析协议）;RARP协议（Reverse Address Resolution Protocol，逆地址解析协议）。重要的设备：路由器。 传输层 ：第一个端到端，即主机到主机的层次。传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输。此外，传输层还要处理端到端的差错控制和流量控制问题。包含的主要协议：TCP协议（Transmission Control Protocol，传输控制协议）、UDP协议（User Datagram Protocol，用户数据报协议）；重要设备：网关。 会话层 ：会话层管理主机之间的会话进程，即负责建立、管理、终止进程之间的会话。会话层还利用在数据中插入校验点来实现数据的同步。 表示层 ：表示层对上层数据或信息进行变换以保证一个主机应用层信息可以被另一个主机的应用程序理解。表示层的数据转换包括数据的加密、压缩、格式转换等。 应用层 ：为操作系统或网络应用程序提供访问网络服务的接口。 会话层、表示层和应用层重点： 数据传输基本单位为报文；包含的主要协议：FTP（文件传送协议）、Telnet（远程登录协议）、DNS（域名解析协议）、SMTP（邮件传送协议），POP3协议（邮局协议），HTTP协议（Hyper Text Transfer Protocol）。 数据封装： 计算机网络性能参数【1】速率 连接在计算机网络上的主机在数字信道上传送数据位数的速率也称为 data rate或 bit rate。 单位是b/s,kbs,Mb/s,Gb/s 【2】带宽 数据通信领域中,数字信道所能传送的最高数据率，单位是b/s,kbs,Mb/s,Gb/s 【3】吞吐量(即总的速率) 即在单位时间内通过某个网络的数据量单位b/s,Mb/s。 【4】时延 【5】时延带宽积 【6】往返时间RTT 从发送方发送数据开始到发送方收到接收方确认 【7】网络利用率 #]]></content>
      <categories>
        <category>计算机网络</category>
        <category>计算机网络理论</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP]]></title>
    <url>%2F2019%2F03%2F17%2FHTTP%2F</url>
    <content type="text"><![CDATA[一 、基础概念URIURI 包含 URL 和 URN。 请求和响应报文1. 请求报文 2. 响应报文 二、HTTP 方法客户端发送的 请求报文 第一行为请求行，包含了方法字段。 GET 获取资源 当前网络请求中，绝大部分使用的是 GET 方法。 HEAD 获取报文首部 和 GET 方法类似，但是不返回报文实体主体部分。 主要用于确认 URL 的有效性以及资源更新的日期时间等。 POST 传输实体主体 POST 主要用来传输数据，而 GET 主要用来获取资源。 更多 POST 与 GET 的比较请见第九章。 PUT 上传文件 由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。 123456PUT /new.html HTTP/1.1Host: example.comContent-type: text/htmlContent-length: 16&lt;p&gt;New File&lt;/p&gt; PATCH 对资源进行部分修改 PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。 1234567PATCH /file.txt HTTP/1.1Host: www.example.comContent-Type: application/exampleIf-Match: "e0023aa4e"Content-Length: 100[description of changes] DELETE 删除文件 与 PUT 功能相反，并且同样不带验证机制。 1DELETE /file.html HTTP/1.1 OPTIONS 查询支持的方法 查询指定的 URL 能够支持的方法。 会返回 Allow: GET, POST, HEAD, OPTIONS 这样的内容。 CONNECT 要求在与代理服务器通信时建立隧道 使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。 1CONNECT www.example.com:443 HTTP/1.1 TRACE 追踪路径 服务器会将通信路径返回给客户端。 发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。 通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪）。 三、HTTP 状态码服务器返回的 响应报文 中第一行为状态行，包含了状态码以及原因短语，用来告知客户端请求的结果。 状态码 类别 含义 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 1XX 信息 100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。 2XX 成功 200 OK 204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。 206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。 3XX 重定向 301 Moved Permanently ：永久性重定向 302 Found ：临时性重定向 303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。 注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。 304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。 307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。 4XX 客户端错误 400 Bad Request ：请求报文中存在语法错误。 401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。 403 Forbidden ：请求被拒绝。 404 Not Found 5XX 服务器错误 500 Internal Server Error ：服务器正在执行请求时发生错误。 503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。 四、HTTP 首部有 4 种类型的首部字段：通用首部字段、请求首部字段、响应首部字段和实体首部字段。 各种首部字段及其含义如下（不需要全记，仅供查阅）： 通用首部字段 首部字段名 说明 Cache-Control 控制缓存的行为 Connection 控制不再转发给代理的首部字段、管理持久连接 Date 创建报文的日期时间 Pragma 报文指令 Trailer 报文末端的首部一览 Transfer-Encoding 指定报文主体的传输编码方式 Upgrade 升级为其他协议 Via 代理服务器的相关信息 Warning 错误通知 请求首部字段 首部字段名 说明 Accept 用户代理可处理的媒体类型 Accept-Charset 优先的字符集 Accept-Encoding 优先的内容编码 Accept-Language 优先的语言（自然语言） Authorization Web 认证信息 Expect 期待服务器的特定行为 From 用户的电子邮箱地址 Host 请求资源所在服务器 If-Match 比较实体标记（ETag） If-Modified-Since 比较资源的更新时间 If-None-Match 比较实体标记（与 If-Match 相反） If-Range 资源未更新时发送实体 Byte 的范围请求 If-Unmodified-Since 比较资源的更新时间（与 If-Modified-Since 相反） Max-Forwards 最大传输逐跳数 Proxy-Authorization 代理服务器要求客户端的认证信息 Range 实体的字节范围请求 Referer 对请求中 URI 的原始获取方 TE 传输编码的优先级 User-Agent HTTP 客户端程序的信息 响应首部字段 首部字段名 说明 Accept-Ranges 是否接受字节范围请求 Age 推算资源创建经过时间 ETag 资源的匹配信息 Location 令客户端重定向至指定 URI Proxy-Authenticate 代理服务器对客户端的认证信息 Retry-After 对再次发起请求的时机要求 Server HTTP 服务器的安装信息 Vary 代理服务器缓存的管理信息 WWW-Authenticate 服务器对客户端的认证信息 实体首部字段 首部字段名 说明 Allow 资源可支持的 HTTP 方法 Content-Encoding 实体主体适用的编码方式 Content-Language 实体主体的自然语言 Content-Length 实体主体的大小 Content-Location 替代对应资源的 URI Content-MD5 实体主体的报文摘要 Content-Range 实体主体的位置范围 Content-Type 实体主体的媒体类型 Expires 实体主体过期的日期时间 Last-Modified 资源的最后修改日期时间 五、具体应用连接管理 1. 短连接与长连接当浏览器访问一个包含多张图片的 HTML 页面时，除了请求访问的 HTML 页面资源，还会请求图片资源。如果每进行一次 HTTP 通信就要新建一个 TCP 连接，那么开销会很大。 长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。 从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close； 在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 Connection : Keep-Alive。 2. 流水线默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到响应之后才会被发出。由于受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。 流水线是在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟。 CookieHTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。 Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。 Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。 1. 用途 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） 2. 创建过程服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。 123456HTTP/1.0 200 OKContent-type: text/htmlSet-Cookie: yummy_cookie=chocoSet-Cookie: tasty_cookie=strawberry[page content] 客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器。 123GET /sample_page.html HTTP/1.1Host: www.example.orgCookie: yummy_cookie=choco; tasty_cookie=strawberry 3. 分类 会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。 持久性 Cookie：指定过期时间（Expires）或有效期（max-age）之后就成为了持久性的 Cookie。 1Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; 4. 作用域Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前文档的主机（不包含子域名）。如果指定了 Domain，则一般包含子域名。例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如 developer.mozilla.org）。 Path 标识指定了主机下的哪些路径可以接受 Cookie（该 URL 路径必须存在于请求 URL 中）。以字符 %x2F (“/“) 作为路径分隔符，子路径也会被匹配。例如，设置 Path=/docs，则以下地址都会匹配： /docs /docs/Web/ /docs/Web/HTTP 5. JavaScript浏览器通过 document.cookie 属性可创建新的 Cookie，也可通过该属性访问非 HttpOnly 标记的 Cookie。 123document.cookie = "yummy_cookie=choco";document.cookie = "tasty_cookie=strawberry";console.log(document.cookie); 6. HttpOnly标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。跨站脚本攻击 (XSS) 常常使用 JavaScript 的 document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。 1Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly 7. Secure标记为 Secure 的 Cookie 只能通过被 HTTPS 协议加密过的请求发送给服务端。但即便设置了 Secure 标记，敏感信息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障。 8. Session除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。 Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。 使用 Session 维护用户登录状态的过程如下： 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中； 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID； 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中； 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。 应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。 9. 浏览器禁用 Cookie此时无法使用 Cookie 来保存用户信息，只能使用 Session。除此之外，不能再将 Session ID 存放到 Cookie 中，而是使用 URL 重写技术，将 Session ID 作为 URL 的参数进行传递。 10. Cookie 与 Session 选择 Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session； Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密； 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。 缓存1. 优点 缓解服务器压力； 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存。 2. 实现方法 让代理服务器进行缓存； 让客户端浏览器进行缓存。 3. Cache-ControlHTTP/1.1 通过 Cache-Control 首部字段来控制缓存。 3.1 禁止进行缓存 no-store 指令规定不能对请求或响应的任何一部分进行缓存。 1Cache-Control: no-store 3.2 强制确认缓存 no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效时才能使用该缓存对客户端的请求进行响应。 1Cache-Control: no-cache 3.3 私有缓存和公共缓存 private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中。 1Cache-Control: private public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在代理服务器中。 1Cache-Control: public 3.4 缓存过期机制 max-age 指令出现在请求报文，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。 max-age 指令出现在响应报文，表示缓存资源在缓存服务器中保存的时间。 1Cache-Control: max-age=31536000 Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。 1Expires: Wed, 04 Jul 2012 08:26:05 GMT 在 HTTP/1.1 中，会优先处理 max-age 指令； 在 HTTP/1.0 中，max-age 指令会被忽略掉。 4. 缓存验证需要先了解 ETag 首部字段的含义，它是资源的唯一标识。URL 不能唯一表示资源，例如 http://www.google.com/ 有中文和英文两个资源，只有 ETag 才能对这两个资源进行唯一标识。 1ETag: "82e22293907ce725faf67773957acd12" 可以将缓存资源的 ETag 值放入 If-None-Match 首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。 1If-None-Match: "82e22293907ce725faf67773957acd12" Last-Modified 首部字段也可以用于缓存验证，它包含在源服务器发送的响应报文中，指示源服务器对资源的最后修改时间。但是它是一种弱校验器，因为只能精确到一秒，所以它通常作为 ETag 的备用方案。如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有实体主体的 304 Not Modified 响应报文。 1Last-Modified: Wed, 21 Oct 2015 07:28:00 GMT 1If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT 内容协商通过内容协商返回最合适的内容，例如根据浏览器的默认语言选择返回中文界面还是英文界面。 1. 类型1.1 服务端驱动型 客户端设置特定的 HTTP 首部字段，例如 Accept、Accept-Charset、Accept-Encoding、Accept-Language，服务器根据这些字段返回特定的资源。 它存在以下问题： 服务器很难知道客户端浏览器的全部信息； 客户端提供的信息相当冗长（HTTP/2 协议的首部压缩机制缓解了这个问题），并且存在隐私风险（HTTP 指纹识别技术）； 给定的资源需要返回不同的展现形式，共享缓存的效率会降低，而服务器端的实现会越来越复杂。 1.2 代理驱动型 服务器返回 300 Multiple Choices 或者 406 Not Acceptable，客户端从中选出最合适的那个资源。 2. Vary1Vary: Accept-Language 在使用内容协商的情况下，只有当缓存服务器中的缓存满足内容协商条件时，才能使用该缓存，否则应该向源服务器请求该资源。 例如，一个客户端发送了一个包含 Accept-Language 首部字段的请求之后，源服务器返回的响应包含 Vary: Accept-Language 内容，缓存服务器对这个响应进行缓存之后，在客户端下一次访问同一个 URL 资源，并且 Accept-Language 与缓存中的对应的值相同时才会返回该缓存。 内容编码内容编码将实体主体进行压缩，从而减少传输的数据量。 常用的内容编码有：gzip、compress、deflate、identity。 浏览器发送 Accept-Encoding 首部，其中包含有它所支持的压缩算法，以及各自的优先级。服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 首部来告知浏览器它选择了哪一种算法。由于该内容协商过程是基于编码类型来选择资源的展现形式的，响应报文的 Vary 首部字段至少要包含 Content-Encoding。 范围请求如果网络出现中断，服务器只发送了一部分数据，范围请求可以使得客户端只请求服务器未发送的那部分数据，从而避免服务器重新发送所有数据。 1. Range在请求报文中添加 Range 首部字段指定请求的范围。 123GET /z4d4kWk.jpg HTTP/1.1Host: i.imgur.comRange: bytes=0-1023 请求成功的话服务器返回的响应包含 206 Partial Content 状态码。 12345HTTP/1.1 206 Partial ContentContent-Range: bytes 0-1023/146515Content-Length: 1024...(binary content) 2. Accept-Ranges响应首部字段 Accept-Ranges 用于告知客户端是否能处理范围请求，可以处理使用 bytes，否则使用 none。 1Accept-Ranges: bytes 3. 响应状态码 在请求成功的情况下，服务器会返回 206 Partial Content 状态码。 在请求的范围越界的情况下，服务器会返回 416 Requested Range Not Satisfiable 状态码。 在不支持范围请求的情况下，服务器会返回 200 OK 状态码。 分块传输编码Chunked Transfer Encoding，可以把数据分割成多块，让浏览器逐步显示页面。 多部分对象集合一份报文主体内可含有多种类型的实体同时发送，每个部分之间用 boundary 字段定义的分隔符进行分隔，每个部分都可以有首部字段。 例如，上传多个表单时可以使用如下方式： 123456789101112Content-Type: multipart/form-data; boundary=AaB03x--AaB03xContent-Disposition: form-data; name="submit-name"Larry--AaB03xContent-Disposition: form-data; name="files"; filename="file1.txt"Content-Type: text/plain... contents of file1.txt ...--AaB03x-- 虚拟主机HTTP/1.1 使用虚拟主机技术，使得一台服务器拥有多个域名，并且在逻辑上可以看成多个服务器。 通信数据转发1. 代理代理服务器接受客户端的请求，并且转发给其它服务器。 使用代理的主要目的是： 缓存 负载均衡 网络访问控制 访问日志记录 代理服务器分为正向代理和反向代理两种： 用户察觉得到正向代理的存在。 而反向代理一般位于内部网络中，用户察觉不到。 2. 网关与代理服务器不同的是，网关服务器会将 HTTP 转化为其它协议进行通信，从而请求其它非 HTTP 服务器的服务。 3. 隧道使用 SSL 等加密手段，在客户端和服务器之间建立一条安全的通信线路。 六、HTTPSHTTP 有以下安全性问题： 使用明文进行通信，内容可能会被窃听； 不验证通信方的身份，通信方的身份有可能遭遇伪装； 无法证明报文的完整性，报文有可能遭篡改。 HTTPS 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信。 通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。 加密1. 对称密钥加密对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。 优点：运算速度快； 缺点：无法安全地将密钥传输给通信方。 2.非对称密钥加密非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。 公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。 非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。 优点：可以更安全地将公开密钥传输给通信发送方； 缺点：运算速度慢。 3. HTTPS 采用的加密方式HTTPS 采用混合的加密机制，使用非对称密钥加密用于传输对称密钥来保证传输过程的安全性，之后使用对称密钥加密进行通信来保证通信过程的效率。（下图中的 Session Key 就是对称密钥） 认证通过使用 证书 来对通信方进行认证。 数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。 服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。 进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。 完整性保护SSL 提供报文摘要功能来进行完整性保护。 HTTP 也提供了 MD5 报文摘要功能，但不是安全的。例如报文内容被篡改之后，同时重新计算 MD5 的值，通信接收方是无法意识到发生了篡改。 HTTPS 的报文摘要功能之所以安全，是因为它结合了加密和认证这两个操作。试想一下，加密之后的报文，遭到篡改之后，也很难重新计算报文摘要，因为无法轻易获取明文。title: ‘HTTP’date: 2019-03-18 13:52:09tags: - 计算机网络 - HTTPcategories: - 计算机网络 - HTTP HTTPS 的缺点 因为需要进行加密解密等过程，因此速度会更慢； 需要支付证书授权的高额费用。 七、HTTP/2.0HTTP/1.x 缺陷HTTP/1.x 实现简单是以牺牲性能为代价的： 客户端需要使用多个连接才能实现并发和缩短延迟； 不会压缩请求和响应首部，从而导致不必要的网络流量； 不支持有效的资源优先级，致使底层 TCP 连接的利用率低下。 二进制分帧层HTTP/2.0 将报文分成 HEADERS 帧和 DATA 帧，它们都是二进制格式的。 在通信过程中，只会有一个 TCP 连接存在，它承载了任意数量的双向数据流（Stream）。 一个数据流（Stream）都有一个唯一标识符和可选的优先级信息，用于承载双向信息。 消息（Message）是与逻辑请求或响应对应的完整的一系列帧。 帧（Frame）是最小的通信单位，来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。 服务端推送HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求 page.html 页面，服务端就把 script.js 和 style.css 等与之相关的资源一起发给客户端。 首部压缩HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。 HTTP/2.0 要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输。 不仅如此，HTTP/2.0 也使用 Huffman 编码对首部字段进行压缩。 八、HTTP/1.1 新特性详细内容请见上文 默认是长连接 支持流水线 支持同时打开多个 TCP 连接 支持虚拟主机 新增状态码 100 支持分块传输编码 新增缓存处理指令 max-age 九、GET 和 POST 比较作用GET 用于获取资源，而 POST 用于传输实体主体。 参数GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。 因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 中文 会转换为 %E4%B8%AD%E6%96%87，而空格会转换为 %20。POST 参数支持标准字符集。 1GET /test/demo_form.asp?name1=value1&amp;name2=value2 HTTP/1.1 123POST /test/demo_form.asp HTTP/1.1Host: w3schools.comname1=value1&amp;name2=value2 安全安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。 GET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。 安全的方法除了 GET 之外还有：HEAD、OPTIONS。 不安全的方法除了 POST 之外还有 PUT、DELETE。 幂等性幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。 所有的安全方法也都是幂等的。 在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。 GET /pageX HTTP/1.1 是幂等的，连续调用多次，客户端接收到的结果都是一样的： 1234GET /pageX HTTP/1.1GET /pageX HTTP/1.1GET /pageX HTTP/1.1GET /pageX HTTP/1.1 POST /add_row HTTP/1.1 不是幂等的，如果调用多次，就会增加多行记录： 123POST /add_row HTTP/1.1 -&gt; Adds a 1nd rowPOST /add_row HTTP/1.1 -&gt; Adds a 2nd rowPOST /add_row HTTP/1.1 -&gt; Adds a 3rd row DELETE /idX/delete HTTP/1.1 是幂等的，即使不同的请求接收到的状态码不一样： 123DELETE /idX/delete HTTP/1.1 -&gt; Returns 200 if idX existsDELETE /idX/delete HTTP/1.1 -&gt; Returns 404 as it just got deletedDELETE /idX/delete HTTP/1.1 -&gt; Returns 404 可缓存如果要对响应进行缓存，需要满足以下条件： 请求报文的 HTTP 方法本身是可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的。 响应报文的状态码是可缓存的，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。 响应报文的 Cache-Control 首部字段没有指定不进行缓存。 XMLHttpRequest为了阐述 POST 和 GET 的另一个区别，需要先了解 XMLHttpRequest： XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。 在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。 而 GET 方法 Header 和 Data 会一起发送。]]></content>
      <categories>
        <category>计算机网络</category>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络-链路层]]></title>
    <url>%2F2019%2F03%2F17%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E9%93%BE%E8%B7%AF%E5%B1%82%2F</url>
    <content type="text"><![CDATA[==数据链路层3个基本功能==封装成帧、透明传输、差错控制 1. 封装成帧将网络层传下来的分组添加首部和尾部，用于标记帧的开始和结束。 2. 透明传输透明表示一个实际存在的事物看起来好像不存在一样。 数据链路层通过控制字符进行帧定界 ==若传输的数据是ASC码中“可打印字符（共95个）”集时，一切正常。若传输的数据不是仅由“可打印字符”组成时，就会出问题，如下图。== 用字节填充法解决透明传输的问题发送端的数据链路层在数据中出现控制字符“SOH”或“EOT”的前面插入一个转义字符“ESC”（其十六进制编码是1B）。 字节填充（byte stuffing）或字符填充（（characterstuffing）——接收端的数据链路层在将数据送往网络层之前删除插入的转义字符。 如果转义字符也出现数据当中，那么应在转义字符前插入一个转义字符。当接收端收到连续的两个转义字符时，就删除其中前面的一个。 3. 差错检测目前数据链路层广泛使用了循环冗余检验（CRC）来检查比特差错。 信道分类1. 点对点信道一对一通信。 因为不会发生碰撞，因此也比较简单，使用 PPP 协议进行控制。 2. 广播信道一对多通信，一个节点发送的数据能够被广播信道上所有的节点接收到。 所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。 主要有两种控制方法进行协调，一个是使用信道复用技术，一是使用 CSMA/CD 协议。 3.组播==MAC 地址==MAC 地址是链路层地址，长度为 6 字节（48 位），用于唯一标识网络适配器（网卡）。 一台主机拥有多少个网络适配器就有多少个 MAC 地址。例如笔记本电脑普遍存在无线网络适配器和有线网络适配器，因此就有两个 MAC 地址。 在局域网中，硬件地址又称为物理地址，或MAC地址。 IEEE的注册管理机构RA负责向厂家分配地址字段的前三个字节（即高位24位）。 前高24位为厂家代号，低24位厂家自行指定 查看电脑的MAC地址： ipconfig /all 修改MAC地址： 打来【网络连接】-【属性】-【高级】-设定指定值 局域网局域网是一种典型的广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。 主要有以太网、令牌环网、FDDI 和 ATM 等局域网技术，目前以太网占领着有线局域网市场。 可以按照网络拓扑结构对局域网进行分类： 以太网以太网是一种星型拓扑结构局域网。 早期使用集线器进行连接，集线器是一种物理层设备， 作用于比特而不是帧，当一个比特到达接口时，集线器重新生成这个比特，并将其能量强度放大，从而扩大网络的传输距离，之后再将这个比特发送到其它所有接口。如果集线器同时收到两个不同接口的帧，那么就发生了碰撞。 目前以太网使用交换机替代了集线器，交换机是一种链路层设备，它不会发生碰撞，能根据 MAC 地址进行存储转发。 以太网帧格式： 类型 ：标记上层使用的协议； 数据 ：长度在 46-1500 之间，如果太小则需要填充； FCS ：帧检验序列，使用的是 CRC 检验方法； 交换机交换机具有自学习能力，学习的是交换表的内容，交换表中存储着 MAC 地址到接口的映射。 正是由于这种自学习能力，因此交换机是一种即插即用设备，不需要网络管理员手动配置交换表内容。 下图中，交换机有 4 个接口，主机 A 向主机 B 发送数据帧时，交换机把主机 A 到接口 1 的映射写入交换表中。为了发送数据帧到 B，先查交换表，此时没有主机 B 的表项，那么主机 A 就发送广播帧，主机 C 和主机 D 会丢弃该帧，主机 B 回应该帧向主机 A 发送数据包时，交换机查找交换表得到主机 A 映射的接口为 1，就发送数据帧到接口 1，同时交换机添加主机 B 到接口 2 的映射。 虚拟局域网虚拟局域网可以建立与物理位置无关的逻辑组，只有在同一个虚拟局域网中的成员才会收到链路层广播信息。 例如下图中 (A1, A2, A3, A4) 属于一个虚拟局域网，A1 发送的广播会被 A2、A3、A4 收到，而其它站点收不到。 使用 VLAN 干线连接来建立虚拟局域网，每台交换机上的一个特殊接口被设置为干线接口，以互连 VLAN 交换机。IEEE 定义了一种扩展的以太网帧格式 802.1Q，它在标准以太网帧上加进了 4 字节首部 VLAN 标签，用于表示该帧属于哪一个虚拟局域网。 ==CSMA/CD 协议(广播信道，一般用于局域网)==CSMA/CD 表示载波监听多点接入 / 碰撞检测。 局域网是一种典型的广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。 主要有以太网、令牌环网、FDDI 和 ATM 等局域网技术，目前以太网占领着有线局域网市场。 可以按照网络拓扑结构对局域网进行分类： 多点接入：随机接入，现在以太网采用 多点接入 ：说明这是总线型网络，许多主机以多点的方式连接到总线上。 载波监听 ：每个主机都必须不停地监听信道。在发送前，如果监听到信道正在使用，就必须等待。 碰撞检测 ：在发送中，如果监听到信道已有其它主机正在发送数据，就表示发生了碰撞。虽然每个主机在发送数据之前都已经监听到信道为空闲，但是由于电磁波的传播时延的存在，还是有可能会发生碰撞。 记端到端的传播时延为 τ，最先发送的站点最多经过 2τ 就可以知道是否发生了碰撞，称 2τ 为 争用期 。只有经过争用期之后还没有检测到碰撞，才能肯定这次发送不会发生碰撞。 当发生碰撞时，站点要停止发送，等待一段时间再发送。这个时间采用 截断二进制指数退避算法 来确定。从离散的整数集合 {0, 1, .., (2k-1)} 中随机取出一个数，记作 r，然后取 r 倍的争用期作为重传等待时间。 ==PPP 协议(点到点信道，一般用于广域网)==互联网用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。 PPP 的帧格式： F 字段为帧的定界符 A 和 C 字段暂时没有意义 FCS 字段是使用 CRC 的检验序列 信息部分的长度不超过 1500]]></content>
      <categories>
        <category>计算机网络</category>
        <category>计算机网络理论</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库原理]]></title>
    <url>%2F2019%2F03%2F17%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[一、数据库常见分类与特点（1） 关系型和非关系型数据库的区别（各自优点） 数据库类型 特性 优点 缺点 关系型数据库SQLite、Oracle、mysql 1、关系型数据库，是指采用了关系模型来组织数据的数据库；2、关系型数据库的最大特点就是事务的一致性；3、简单来说，关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织。 1、容易理解：二维表结构是非常贴近逻辑世界一个概念，关系模型相对网状、层次等其他模型来说更容易理解；2、使用方便：通用的SQL语言使得操作关系型数据库非常方便；3、易于维护：丰富的完整性(实体完整性、参照完整性和用户定义的完整性)大大减低了数据冗余和数据不一致的概率；4、支持SQL，可用于复杂的查询。 1、为了维护一致性所付出的巨大代价就是其读写性能比较差；2、固定的表结构；3、高并发读写需求；4、海量数据的高效率读写； 非关系型数据库MongoDb、redis、HBase 1、使用键值对存储数据；2、分布式；3、一般不支持ACID特性；4、非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合。 1、无需经过sql层的解析，读写性能很高；2、基于键值对，数据没有耦合性，容易扩展；3、存储数据的格式：nosql的存储格式是key,value形式、文档形式、图片形式等等，文档形式、图片形式等等，而关系型数据库则只支持基础类型。 1、不提供sql支持，学习和使用成本较高；2、无事务处理，附加功能bi和报表等支持也不好； 注1：数据库事务必须具备ACID特性，ACID是Atomic原子性，Consistency一致性，Isolation隔离性，Durability持久性。 注2：数据的持久存储，尤其是海量数据的持久存储，还是需要一种关系数据库。 二、事务概念及ACID事务可以保证多个操作原子性，要么全成功，要么全失败。对于数据库来说事务保证批量的DML要么全成功，要么全失败。事务具有四个特征ACID a) 原子性（Atomicity） ​ 整个事务中的所有操作，必须作为一个单元全部完成（或全部取消）。 b) 一致性（Consistency） ​ 在事务开始之前与结束之后，数据库都保持一致状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。 c) 隔离性(Isolation) ​ 一个事务不会影响其他事务的运行。 d) 持久性(Durability) ​ 在事务完成以后，该事务对数据库所作的更改将持久地保存在数据库之中，并不会被回滚。 事务中存在一些概念： a) 事务（Transaction）：一批操作（一组DML） b) 开启事务（Start Transaction） c) 回滚事务（rollback） d) 提交事务（commit） e) SET AUTOCOMMIT：禁用或启用事务的自动提交模式 注意：rollback，或者commit后事务就结束了。 三、事务的隔离性• 事务的隔离级别决定了事务之间可见的级别。 一致性问题：• 当多个客户端并发地访问同一个表时，可能出现下面的一致性问题： – 脏读（Dirty Read） ​ 一个事务开始读取了某行数据，但是另外一个事务已经更新了此数据但没有能够及时提交(最终可能提交也可能回滚)，这就出现了脏读取。 – 不可重复读（Non-repeatable Read） ​ 在同一个事务中，同一个读操作对同一个数据的前后两次读取产生了不同的结果，这就是不可重复读。 例如： 在事务A中，读取到张三的工资为5000，操作没有完成，事务还没提交。与此同时，事务B把张三的工资改为8000，并提交了事务。随后，在事务A中，再次读取张三的工资，此时工资变为8000。在一个事务中前后两次读取的结果并不致，导致了不可重复读。 – 幻读（Phantom Read） ​ 幻像读是指在同一个事务中以前没有的行，由于其他事务的提交而出现的新行。 例如: 目前工资为5000的员工有10人，事务A读取所有工资为5000的人数为10人。此时，事务B插入一条工资也为5000的记录。这是，事务A再次读取工资为5000的员工，记录为11人。此时产生了幻读。 四个隔离级别：InnoDB 实现了四个隔离级别，用以控制事务所做的修改，并将修改通告至其它并发的事务： – 读未提交（READ UMCOMMITTED） ​ 允许一个事务可以看到其他事务未提交的修改。 – 读已提交（READ COMMITTED） ​ 允许一个事务只能看到其他事务已经提交的修改，未提交的修改是不可见的。 – 可重复读（REPEATABLE READ） ​ 确保如果在一个事务中执行两次相同的SELECT语句，都能得到相同的结果，不管其他事务是否提交这些修改。 （银行总账） ​ 该隔离级别为InnoDB的缺省设置。 – 串行化（SERIALIZABLE） 【序列化】 ​ 将一个事务与其他事务完全地隔离。 例:A可以开启事物,B也可以开启事物 A在事物中执行DML语句时,未提交 B不以执行DML,DQL语句 隔离级别与一致性问题的关系： 隔离级别 脏读 不可重复读 幻影读 未提交读 √ √ √ 提交读 × √ √ 可重复读 × × √ 可串行化 × × × 三、范式【1】第一范式属性(字段)不可分割。(例如某个字段存放的地址，不能单独存放地址，应该是拆分了存储。) 【2】第二范式(确保表中的每列都和主键相关)【符合第一范式，同时非主属性完全依赖于主键】 说明：表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。 订单信息表： 这样就产生一个问题：这个表中是以订单编号和商品编号作为联合主键。这样在该表中商品名称、单位、商品价格等信息不与该表的主键相关，而仅仅是与商品编号相关。所以在这里违反了第二范式的设计原则。 而如果把这个订单信息表进行拆分，把商品信息分离到另一个表中，把订单项目表也分离到另一个表中，就非常完美了。如下所示。 【3】第三范式(确保每列都和主键列直接相关,而不是间接相关)【符合2NF，并且消除传递依赖】 比如在设计一个订单数据表的时候，可以将客户编号作为一个外键和订单表建立相应的关系。而不可以在订单表中添加关于客户其它信息（比如姓名、所属公司等）的字段。如下面这两个表所示的设计就是一个满足第三范式的数据库表。 这样在查询订单信息的时候，就可以使用客户编号来引用客户信息表中的记录，也不必在订单信息表中多次输入客户信息的内容，减小了数据冗余。 四、锁锁粒度MySQL 中提供了两种封锁粒度：行级锁以及表级锁。 应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。 但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。 在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。 锁类型1. 读写锁 排它锁（Exclusive），简写为 X 锁，又称写锁。 共享锁（Shared），简写为 S 锁，又称读锁。 有以下两个规定： 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。 锁的兼容关系如下： - X S X × × S × √ 2. 意向锁使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。 在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。 意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定： 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。 通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。 各种锁的兼容关系如下： - X IX S IS X × × × × IX × √ × √ S × × √ √ IS × √ √ √ 解释如下： 任意 IS/IX 锁之间都是兼容的，因为它们只是表示想要对表加锁，而不是真正加锁； S 锁只与 S 锁和 IS 锁兼容，也就是说事务 T 想要对数据行加 S 锁，其它事务可以已经获得对表或者表中的行的 S 锁。 锁协议1. 三级封锁协议一级封锁协议 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。 可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 T1 T2 lock-x(A) read A=20 lock-x(A) wait write A=19 . commit . unlock-x(A) . obtain read A=19 write A=21 commit unlock-x(A) 二级封锁协议 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。 可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 T1 T2 lock-x(A) read A=20 write A=19 lock-s(A) wait rollback . A=20 . unlock-x(A) . obtain read A=20 unlock-s(A) commit 三级封锁协议 在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。 可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。 T1 T2 lock-s(A) read A=20 lock-x(A) wait read A=20 . commit . unlock-s(A) . obtain read A=20 write A=19 commit unlock-X(A) 2. 两段锁协议加锁和解锁分为两个阶段进行。 可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。 事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。 1lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B) 但不是必要条件，例如以下操作不满足两段锁协议，但是它还是可串行化调度。 1lock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C) MySQL 隐式与显示锁定MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 InnoDB 也可以使用特定的语句进行显示锁定： 12SELECT ... LOCK In SHARE MODE;SELECT ... FOR UPDATE; 五、多版本并发控制多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 版本号 系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号：事务开始时的系统版本号。 隐藏的列MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号： 创建版本号：指示创建一个数据行的快照时的系统版本号； 删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。 Undo 日志MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。 实现过程以下实现过程针对可重复读隔离级别。 当开始一个事务时，该事务的版本号肯定大于当前所有数据行快照的创建版本号，理解这一点很关键。数据行快照的创建版本号是创建数据行快照时的系统版本号，系统版本号随着创建事务而递增，因此新创建一个事务时，这个事务的系统版本号比之前的系统版本号都大，也就是比所有数据行快照的创建版本号都大。 1. SELECT多个事务必须读取到同一个数据行的快照，并且这个快照是距离现在最近的一个有效快照。但是也有例外，如果有一个事务正在修改该数据行，那么它可以读取事务本身所做的修改，而不用和其它事务的读取结果一致。 把没有对一个数据行做修改的事务称为 T，T 所要读取的数据行快照的创建版本号必须小于 T 的版本号，因为如果大于或者等于 T 的版本号，那么表示该数据行快照是其它事务的最新修改，因此不能去读取它。除此之外，T 所要读取的数据行快照的删除版本号必须大于 T 的版本号，因为如果小于等于 T 的版本号，那么表示该数据行快照是已经被删除的，不应该去读取它。 2. INSERT将当前系统版本号作为数据行快照的创建版本号。 3. DELETE将当前系统版本号作为数据行快照的删除版本号。 4. UPDATE将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行 DELETE 后执行 INSERT。 快照读与当前读1. 快照读使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。 1select * from table ...; 2. 当前读读取的是最新的数据，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁。 12345select * from table where ? lock in share mode;select * from table where ? for update;insert;update;delete; 六、Next-Key LocksNext-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。 MVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。 Record Locks锁定一个记录上的索引，而不是记录本身。 如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。 Gap Locks锁定索引之间的间隙，但是不包含索引本身。例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。 1SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE; Next-Key Locks它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间： 12345(-∞, 10](10, 11](11, 13](13, 20](20, +∞) 七、关系数据库设计理论函数依赖记 A-&gt;B 表示 A 函数决定 B，也可以说 B 函数依赖于 A。 如果 {A1，A2，… ，An} 是关系的一个或多个属性的集合，该集合函数决定了关系的其它所有属性并且是最小的，那么该集合就称为键码。 对于 A-&gt;B，如果能找到 A 的真子集 A’，使得 A’-&gt; B，那么 A-&gt;B 就是部分函数依赖，否则就是完全函数依赖。 对于 A-&gt;B，B-&gt;C，则 A-&gt;C 是一个传递函数依赖。 异常以下的学生课程关系的函数依赖为 {Sno, Cname} -&gt; {Sname, Sdept, Mname, Grade}，键码为 {Sno, Cname}。也就是说，确定学生和课程之后，就能确定其它信息。 Sno Sname Sdept Mname Cname Grade 1 学生-1 学院-1 院长-1 课程-1 90 2 学生-2 学院-2 院长-2 课程-2 80 2 学生-2 学院-2 院长-2 课程-1 100 3 学生-3 学院-2 院长-2 课程-2 95 不符合范式的关系，会产生很多异常，主要有以下四种异常： 冗余数据：例如 学生-2 出现了两次。 修改异常：修改了一个记录中的信息，但是另一个记录中相同的信息却没有被修改。 删除异常：删除一个信息，那么也会丢失其它信息。例如删除了 课程-1 需要删除第一行和第三行，那么 学生-1 的信息就会丢失。 插入异常：例如想要插入一个学生的信息，如果这个学生还没选课，那么就无法插入。 八、ER 图Entity-Relationship，有三个组成部分：实体、属性、联系。 用来进行关系型数据库系统的概念设计。 实体的三种联系包含一对一，一对多，多对多三种。 如果 A 到 B 是一对多关系，那么画个带箭头的线段指向 B； 如果是一对一，画两个带箭头的线段； 如果是多对多，画两个不带箭头的线段。 下图的 Course 和 Student 是一对多的关系。 表示出现多次的关系一个实体在联系出现几次，就要用几条线连接。 下图表示一个课程的先修关系，先修关系出现两个 Course 实体，第一个是先修课程，后一个是后修课程，因此需要用两条线来表示这种关系。 联系的多向性虽然老师可以开设多门课，并且可以教授多名学生，但是对于特定的学生和课程，只有一个老师教授，这就构成了一个三元联系。 表示子类用一个三角形和两条线来连接类和子类，与子类有关的属性和联系都连到子类上，而与父类和子类都有关的连到父类上。 参考资料 AbrahamSilberschatz, HenryF.Korth, S.Sudarshan, 等. 数据库系统概念 [M]. 机械工业出版社, 2006.]]></content>
      <categories>
        <category>数据库</category>
        <category>数据库原理</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2019%2F03%2F15%2FRedis%2F</url>
    <content type="text"><![CDATA[一、概述Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。 键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。 Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。 二、数据类型 数据类型 可以存储的值 操作 STRING 字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作 对整数和浮点数执行自增或者自减操作 LIST 列表 从两端压入或者弹出元素 对单个或者多个元素进行修剪， 只保留一个范围内的元素 SET 无序集合 添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素 HASH 包含键值对的无序散列表 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 ZSET 有序集合 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 What Redis data structures look like STRING 12345678&gt; set hello worldOK&gt; get hello"world"&gt; del hello(integer) 1&gt; get hello(nil) LIST 123456789101112131415161718192021&gt; rpush list-key item(integer) 1&gt; rpush list-key item2(integer) 2&gt; rpush list-key item(integer) 3&gt; lrange list-key 0 -11) "item"2) "item2"3) "item"&gt; lindex list-key 1"item2"&gt; lpop list-key"item"&gt; lrange list-key 0 -11) "item2"2) "item" SET 123456789101112131415161718192021222324252627&gt; sadd set-key item(integer) 1&gt; sadd set-key item2(integer) 1&gt; sadd set-key item3(integer) 1&gt; sadd set-key item(integer) 0&gt; smembers set-key1) "item"2) "item2"3) "item3"&gt; sismember set-key item4(integer) 0&gt; sismember set-key item(integer) 1&gt; srem set-key item2(integer) 1&gt; srem set-key item2(integer) 0&gt; smembers set-key1) "item"2) "item3" HASH 123456789101112131415161718192021222324&gt; hset hash-key sub-key1 value1(integer) 1&gt; hset hash-key sub-key2 value2(integer) 1&gt; hset hash-key sub-key1 value1(integer) 0&gt; hgetall hash-key1) "sub-key1"2) "value1"3) "sub-key2"4) "value2"&gt; hdel hash-key sub-key2(integer) 1&gt; hdel hash-key sub-key2(integer) 0&gt; hget hash-key sub-key1"value1"&gt; hgetall hash-key1) "sub-key1"2) "value1" ZSET 12345678910111213141516171819202122232425&gt; zadd zset-key 728 member1(integer) 1&gt; zadd zset-key 982 member0(integer) 1&gt; zadd zset-key 982 member0(integer) 0&gt; zrange zset-key 0 -1 withscores1) "member1"2) "728"3) "member0"4) "982"&gt; zrangebyscore zset-key 0 800 withscores1) "member1"2) "728"&gt; zrem zset-key member1(integer) 1&gt; zrem zset-key member1(integer) 0&gt; zrange zset-key 0 -1 withscores1) "member0"2) "982" 三、数据结构字典dictht 是一个散列表结构，使用拉链法解决哈希冲突。 12345678/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. */typedef struct dictht &#123; dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used;&#125; dictht; 12345678910typedef struct dictEntry &#123; void *key; union &#123; void *val; uint64_t u64; int64_t s64; double d; &#125; v; struct dictEntry *next;&#125; dictEntry; Redis 的字典 dict 中包含两个哈希表 dictht，这是为了方便进行 rehash 操作。在扩容时，将其中一个 dictht 上的键值对 rehash 到另一个 dictht 上面，完成之后释放空间并交换两个 dictht 的角色。 1234567typedef struct dict &#123; dictType *type; void *privdata; dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ unsigned long iterators; /* number of iterators currently running */&#125; dict; rehash 操作不是一次性完成，而是采用渐进方式，这是为了避免一次性执行过多的 rehash 操作给服务器带来过大的负担。 渐进式 rehash 通过记录 dict 的 rehashidx 完成，它从 0 开始，然后每执行一次 rehash 都会递增。例如在一次 rehash 中，要把 dict[0] rehash 到 dict[1]，这一次会把 dict[0] 上 table[rehashidx] 的键值对 rehash 到 dict[1] 上，dict[0] 的 table[rehashidx] 指向 null，并令 rehashidx++。 在 rehash 期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式 rehash。 采用渐进式 rehash 会导致字典中的数据分散在两个 dictht 上，因此对字典的查找操作也需要到对应的 dictht 去执行。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/* Performs N steps of incremental rehashing. Returns 1 if there are still * keys to move from the old to the new hash table, otherwise 0 is returned. * * Note that a rehashing step consists in moving a bucket (that may have more * than one key as we use chaining) from the old to the new hash table, however * since part of the hash table may be composed of empty spaces, it is not * guaranteed that this function will rehash even a single bucket, since it * will visit at max N*10 empty buckets in total, otherwise the amount of * work it does would be unbound and the function may block for a long time. */int dictRehash(dict *d, int n) &#123; int empty_visits = n * 10; /* Max number of empty buckets to visit. */ if (!dictIsRehashing(d)) return 0; while (n-- &amp;&amp; d-&gt;ht[0].used != 0) &#123; dictEntry *de, *nextde; /* Note that rehashidx can't overflow as we are sure there are more * elements because ht[0].used != 0 */ assert(d-&gt;ht[0].size &gt; (unsigned long) d-&gt;rehashidx); while (d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) &#123; d-&gt;rehashidx++; if (--empty_visits == 0) return 1; &#125; de = d-&gt;ht[0].table[d-&gt;rehashidx]; /* Move all the keys in this bucket from the old to the new hash HT */ while (de) &#123; uint64_t h; nextde = de-&gt;next; /* Get the index in the new hash table */ h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; d-&gt;ht[0].used--; d-&gt;ht[1].used++; de = nextde; &#125; d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; d-&gt;rehashidx++; &#125; /* Check if we already rehashed the whole table... */ if (d-&gt;ht[0].used == 0) &#123; zfree(d-&gt;ht[0].table); d-&gt;ht[0] = d-&gt;ht[1]; _dictReset(&amp;d-&gt;ht[1]); d-&gt;rehashidx = -1; return 0; &#125; /* More to rehash... */ return 1;&#125; 跳跃表是有序集合的底层实现之一。 跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。 在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。下图演示了查找 22 的过程。 与红黑树等平衡树相比，跳跃表具有以下优点： 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性； 更容易实现； 支持无锁操作。 四、使用场景计数器可以对 String 进行自增自减运算，从而实现计数器功能。 Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。 缓存将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。 查找表例如 DNS 记录就很适合使用 Redis 进行存储。 查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。 消息队列List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息 不过最好使用 Kafka、RabbitMQ 等消息中间件。 会话缓存可以使用 Redis 来统一存储多台应用服务器的会话信息。 当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。 分布式锁实现在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。 可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。 其它Set 可以实现交集、并集等操作，从而实现共同好友等功能。 ZSet 可以实现有序性操作，从而实现排行榜等功能。 五、Redis 与 Memcached两者都是非关系型内存键值数据库，主要有以下不同： 数据类型Memcached 仅支持字符串类型，而 Redis 支持五种不同的数据类型，可以更灵活地解决问题。 数据持久化Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。 分布式Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。 Redis Cluster 实现了分布式的支持。 内存管理机制 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。 Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。 六、键的过期时间Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。 对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。 七、数据淘汰策略可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。 Redis 具体有 6 种淘汰策略： 策略 描述 volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random 从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰 allkeys-random 从所有数据集中任意选择数据进行淘汰 noeviction 禁止驱逐数据 作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。 使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。 Redis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。 八、持久化Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。 RDB 持久化将某个时间点的所有数据都存放到硬盘上。 可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。 如果系统发生故障，将会丢失最后一次创建快照之后的数据。 如果数据量很大，保存快照的时间会很长。 AOF 持久化将写命令添加到 AOF 文件（Append Only File）的末尾。 使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项： 选项 同步频率 always 每个写命令都同步 everysec 每秒同步一次 no 让操作系统来决定何时同步 always 选项会严重减低服务器的性能； everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。 随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。 九、事务一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。 事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。 Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。 十、事件Redis 服务器是一个事件驱动程序。 文件事件服务器通过套接字与客户端或者其它服务器进行通信，文件事件就是对套接字操作的抽象。 Redis 基于 Reactor 模式开发了自己的网络事件处理器，使用 I/O 多路复用程序来同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会根据套接字产生的事件类型调用相应的事件处理器。 时间事件服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。 时间事件又分为： 定时事件：是让一段程序在指定的时间之内执行一次； 周期性事件：是让一段程序每隔指定时间就执行一次。 Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。 事件的调度与执行服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能一直监听，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。 事件调度与执行由 aeProcessEvents 函数负责，伪代码如下： 12345678910111213141516def aeProcessEvents(): # 获取到达时间离当前时间最接近的时间事件 time_event = aeSearchNearestTimer() # 计算最接近的时间事件距离到达还有多少毫秒 remaind_ms = time_event.when - unix_ts_now() # 如果事件已到达，那么 remaind_ms 的值可能为负数，将它设为 0 if remaind_ms &lt; 0: remaind_ms = 0 # 根据 remaind_ms 的值，创建 timeval timeval = create_timeval_with_ms(remaind_ms) # 阻塞并等待文件事件产生，最大阻塞时间由传入的 timeval 决定 aeApiPoll(timeval) # 处理所有已产生的文件事件 procesFileEvents() # 处理所有已到达的时间事件 processTimeEvents() 将 aeProcessEvents 函数置于一个循环里面，加上初始化和清理函数，就构成了 Redis 服务器的主函数，伪代码如下： 12345678def main(): # 初始化服务器 init_server() # 一直处理事件，直到服务器关闭为止 while server_is_not_shutdown(): aeProcessEvents() # 服务器关闭，执行清理操作 clean_server() 从事件处理的角度来看，服务器运行流程如下： 十一、复制通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。 一个从服务器只能有一个主服务器，并且不支持主主复制。 连接过程 主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令； 从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令； 主服务器每执行一次写命令，就向从服务器发送相同的写命令。 主从链随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。 十二、SentinelSentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。 十三、分片分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。 假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，… ，有不同的方式来选择一个指定的键存储在哪个实例中。 最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。 根据执行分片的位置，可以分为三种分片方式： 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。 服务器分片：Redis Cluster。 十四、一个简单的论坛系统分析该论坛系统功能如下： 可以发布文章； 可以对文章进行点赞； 在首页可以按文章的发布时间或者文章的点赞数进行排序显示。 文章信息文章包括标题、作者、赞数等信息，在关系型数据库中很容易构建一张表来存储这些信息，在 Redis 中可以使用 HASH 来存储每种信息以及其对应的值的映射。 Redis 没有关系型数据库中的表这一概念来将同种类型的数据存放在一起，而是使用命名空间的方式来实现这一功能。键名的前面部分存储命名空间，后面部分的内容存储 ID，通常使用 : 来进行分隔。例如下面的 HASH 的键名为 article:92617，其中 article 为命名空间，ID 为 92617。 点赞功能当有用户为一篇文章点赞时，除了要对该文章的 votes 字段进行加 1 操作，还必须记录该用户已经对该文章进行了点赞，防止用户点赞次数超过 1。可以建立文章的已投票用户集合来进行记录。 为了节约内存，规定一篇文章发布满一周之后，就不能再对它进行投票，而文章的已投票集合也会被删除，可以为文章的已投票集合设置一个一周的过期时间就能实现这个规定。 对文章进行排序为了按发布时间和点赞数进行排序，可以建立一个文章发布时间的有序集合和一个文章点赞数的有序集合。（下图中的 score 就是这里所说的点赞数；下面所示的有序集合分值并不直接是时间和点赞数，而是根据时间和点赞数间接计算出来的）]]></content>
      <categories>
        <category>数据库</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL]]></title>
    <url>%2F2019%2F03%2F15%2FMySQL%2F</url>
    <content type="text"><![CDATA[一、MySql常用数据类型 类型 描述 Char(长度) 定长字符串，存储空间大小固定，适合作为主键或外键 Varchar(长度) 变长字符串，存储空间等于实际数据空间 double(有效数字位数，小数位) 数值型 Float(有效数字位数，小数位) 数值型 Int(长度) 整型 bigint(长度) 长整型 Date 日期型 BLOB Binary Large OBject（二进制大对象） CLOB Character Large OBject（字符大对象） 其它………………… 二、存储引擎MyISAM、InnoDB、MEMORYMyISAM:它不支持事务，也不支持外键，尤其是访问速度快，对事务完整性没有要求或者以SELECT、INSERT为主的应用基本都可以使用这个引擎来创建表。 InnoDB:InnoDB是一个健壮的事务型存储引擎,他引入了行级锁和外键约束。一般来说，如果需要事务支持，并且有较高的并发读取频率，InnoDB是不错的选择。 MEMORY：使用MySQL Memory存储引擎的出发点是速度。为得到最快的响应时间，采用的逻辑存储介质是系统内存。 一般在以下几种情况下使用Memory存储引擎：1.目标数据较小，而且被非常频繁地访问。2.如果数据是临时的，而且要求必须立即可用，那么就可以存放在内存表中。3.存储在Memory表中的数据如果突然丢失，不会对应用服务产生实质的负面影响。 三、数据库的索引类型，数据库索引的作用数据库索引好比是一本书前面的目录，能加快数据库的查询速度。索引是对数据库表中一个或多个列（例如，employee 表的姓氏 (lname) 列）的值进行排序的结构。如果想按特定职员的姓来查找他或她，则与在表中搜索所有的行相比，索引有助于更快地获取信息。 优点：大大加快数据的检索速度; 创建唯一性索引，保证数据库表中每一行数据的唯一性；加速表和表之间的连接; 在使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间。 缺点：索引需要占用数据表以外的物理存储空间；创建索引和维护索引要花费一定的时间；当对表进行更新操作时，索引需要被重建，这样降低了数据的维护速度。 mysql索引类型Normal,Unique,Full Text区别：normal：表示普通索引 unique：表示唯一的，不允许重复的索引，如果该字段信息保证不会重复例如身份证号用作索引时，可设置为unique full textl: 表示 全文搜索的索引。 FULLTEXT 用于搜索很长一篇文章的时候，效果最好。用在比较短的文本，如果就一两行字的，普通的 INDEX 也可以。 总结，索引的类别由建立索引的字段内容特性来决定，通常normal最常见。 btree索引和hash索引的区别：hash 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引。 既然 Hash 索引的效率要比 B-Tree 高很多，为什么大家不都用 Hash 索引而还要使用 B-Tree 索引呢？ Hash 索引本身由于其特殊性也带来了很多限制和弊端，主要有以下这些。 （1）Hash 索引仅仅能满足”=”,”IN”和”&lt;=&gt;”查询，不能使用范围查询。 由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。 （2）Hash 索引无法被用来避免数据的排序操作。 由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算； （3）Hash 索引不能利用部分索引键查询。 对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。 （4）Hash 索引在任何时候都不能避免表扫描。 前面已经知道，Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值**，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。当Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。** 四、聚集索引和非聚集索引的区别1)聚集索引表示表中存储的数据按照索引的顺序存储，检索效率比非聚集索引高，但对数据更新影响较大。非聚集索引表示数据存储在一个地方，索引存储在另一个地方，索引带有指针指向数据的存储位置，非聚集索引检索效率比聚集索引低，但对数据更新影响较小。 2)聚集索引一个表只能有一个，而非聚集索引一个表可以存在多个。聚集索引存储记录是物理上连续存在，而非聚集索引是逻辑上的连续，物理存储并不连续。 五、索引的数据结构B+ Tree 原理1. 数据结构B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。 B+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。 在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。 2. 操作进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。 插入删除操作会破坏平衡树的平衡性，因此在插入删除操作之后，需要对树进行一个分裂、合并、旋转等操作来维护平衡性。 3. 与红黑树的比较红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，主要有以下两个原因： （一）更少的查找次数 平衡树查找操作的时间复杂度和树高 h 相关，O(h)=O(logdN)，其中 d 为每个节点的出度。 红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多，查找的次数也就更多。 （二）利用磁盘预读特性 为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。 操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。并且可以利用预读特性，相邻的节点也能够被预先载入。 MySQL 索引索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。 1. B+Tree 索引是大多数 MySQL 存储引擎的默认索引类型。 因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。 因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。 可以指定多个列作为索引列，多个索引列共同组成键。 适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。 InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。 辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。 2. 哈希索引哈希索引能以 O(1) 时间进行查找，但是失去了有序性： 无法用于排序与分组； 只支持精确查找，无法用于部分查找和范围查找。 InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。 3. 全文索引MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。 查找条件使用 MATCH AGAINST，而不是普通的 WHERE。 全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。 InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。 4. 空间数据索引MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。 必须使用 GIS 相关的函数来维护数据。 索引优化1. 独立的列在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。 例如下面的查询不能使用 actor_id 列的索引： 1SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 2. 多列索引在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。 12SELECT film_id, actor_ id FROM sakila.film_actorWHERE actor_id = 1 AND film_id = 1; 3. 索引列的顺序让选择性最强的索引列放在前面。 索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。 例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。 1234SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity,COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity,COUNT(*)FROM payment; 123 staff_id_selectivity: 0.0001customer_id_selectivity: 0.0373 COUNT(*): 16049 4. 前缀索引对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。 前缀长度的选取需要根据索引选择性来确定。 5. 覆盖索引索引包含所有需要查询的字段的值。 具有以下优点： 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。 一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。 索引的优点 大大减少了服务器需要扫描的数据行数。 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。 索引的使用条件 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效； 对于中到大型的表，索引就非常有效； 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。 六、查询性能优化使用 Explain 进行分析Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。 比较重要的字段有： select_type : 查询类型，有简单查询、联合查询、子查询等 key : 使用的索引 rows : 扫描的行数 优化数据访问1. 减少请求的数据量 只返回必要的列：最好不要使用 SELECT * 语句。 只返回必要的行：使用 LIMIT 语句来限制返回的数据。 缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。 2. 减少服务器端扫描的行数最有效的方式是使用索引来覆盖查询。 重构查询方式1. 切分大查询一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。 1DELETE FROM messages WHERE create &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH); 12345rows_affected = 0do &#123; rows_affected = do_query( "DELETE FROM messages WHERE create &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000")&#125; while rows_affected &gt; 0 2. 分解大连接查询将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有： 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。 减少锁竞争； 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。 1234SELECT * FROM tabJOIN tag_post ON tag_post.tag_id=tag.idJOIN post ON tag_post.post_id=post.idWHERE tag.tag='mysql'; 123SELECT * FROM tag WHERE tag='mysql';SELECT * FROM tag_post WHERE tag_id=1234;SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904); 七、切分水平切分水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。 当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。 垂直切分垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。 在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。 Sharding 策略 哈希取模：hash(key) % N； 范围：可以是 ID 范围也可以是时间范围； 映射表：使用单独的一个数据库来存储映射关系。 Sharding 存在的问题1. 事务问题使用分布式事务来解决，比如 XA 接口。 2. 连接可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。 3. ID 唯一性 使用全局唯一 ID（GUID） 为每个分片指定一个 ID 范围 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法) 八、复制主从复制主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。 binlog 线程 ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。 I/O 线程 ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。 SQL 线程 ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。 读写分离主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。 读写分离能提高性能的原因在于： 主从服务器负责各自的读和写，极大程度缓解了锁的争用； 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销； 增加冗余，提高可用性。 读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。 参考资料 BaronScbwartz, PeterZaitsev, VadimTkacbenko, 等. 高性能 MySQL[M]. 电子工业出版社, 2013.]]></content>
      <categories>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
</search>
